{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# March Data Crunch Madness - Black Boxers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (auc, classification_report, roc_auc_score, accuracy_score,\n",
    "                             f1_score, log_loss, roc_curve, confusion_matrix, precision_score, recall_score)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3445, 100)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('NCAA_Tourney_2021.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed Differential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsample1 = df.copy()\n",
    "dfsample1['seed_diff'] = dfsample1['team1_seed'] - dfsample1['team2_seed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three Point Differential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsample1[\"3_point_diff\"] = (dfsample1[\"team1_fg3pct\"]+dfsample1[\"team2_oppfg3pct\"])/2-(dfsample1[\"team2_fg3pct\"]+dfsample1['team1_oppfg3pct'])/2\n",
    "dfsample2 = dfsample1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Correlation with DV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsample3 = df.copy()\n",
    "dfsample3 = dfsample3[['team1_id', 'team2_id', 'game_id','team1_pt_school_ncaa','team1_pt_overall_ncaa','team1_pt_school_s16','team1_pt_overall_s16','team1_pt_school_ff','team1_pt_overall_ff','team1_pt_career_school_wins',\n",
    "             'team1_pt_career_school_losses','team1_pt_career_overall_wins','team1_pt_career_overall_losses','team1_pt_team_season_wins','team1_pt_team_season_losses','team1_pt_coach_season_wins','team1_pt_coach_season_losses',\n",
    "            'team2_pt_school_ncaa','team2_pt_overall_ncaa','team2_pt_school_s16','team2_pt_overall_s16','team2_pt_school_ff','team2_pt_overall_ff','team2_pt_career_school_wins','team2_pt_career_school_losses','team2_pt_career_overall_wins','team2_pt_career_overall_losses','team2_pt_team_season_wins',\n",
    "             'team2_pt_team_season_losses','team2_pt_coach_season_wins','team2_pt_coach_season_losses','team1_fg2pct','team1_fg3pct','team1_ftpct','team1_blockpct','team1_oppfg2pct','team1_oppfg3pct','team1_oppftpct',\n",
    "             'team1_oppblockpct','team1_f3grate','team1_oppf3grate','team1_arate','team1_opparate','team1_stlrate','team1_oppstlrate','team2_fg2pct','team2_fg3pct','team2_ftpct','team2_blockpct','team2_oppfg2pct','team2_oppfg3pct','team2_oppftpct','team2_oppblockpct','team2_f3grate','team2_oppf3grate','team2_arate',\n",
    "             'team2_opparate','team2_stlrate','team2_oppstlrate','team1_tempo','team1_adjtempo','team1_oe','team1_adjoe','team1_de','team1_adjde','team2_tempo','team2_adjtempo','team2_oe','team2_adjoe','team2_de','team2_adjde']]\n",
    "#dfsample3\n",
    "\n",
    "nvar_list = ['team1_pt_school_ncaa','team1_pt_overall_ncaa','team1_pt_school_s16','team1_pt_overall_s16','team1_pt_school_ff','team1_pt_overall_ff','team1_pt_career_school_wins',\n",
    "             'team1_pt_career_school_losses','team1_pt_career_overall_wins','team1_pt_career_overall_losses','team1_pt_team_season_wins','team1_pt_team_season_losses','team1_pt_coach_season_wins','team1_pt_coach_season_losses',\n",
    "            'team2_pt_school_ncaa','team2_pt_overall_ncaa','team2_pt_school_s16','team2_pt_overall_s16','team2_pt_school_ff','team2_pt_overall_ff','team2_pt_career_school_wins','team2_pt_career_school_losses','team2_pt_career_overall_wins','team2_pt_career_overall_losses','team2_pt_team_season_wins',\n",
    "             'team2_pt_team_season_losses','team2_pt_coach_season_wins','team2_pt_coach_season_losses','team1_fg2pct','team1_fg3pct','team1_ftpct','team1_blockpct','team1_oppfg2pct','team1_oppfg3pct','team1_oppftpct',\n",
    "             'team1_oppblockpct','team1_f3grate','team1_oppf3grate','team1_arate','team1_opparate','team1_stlrate','team1_oppstlrate','team2_fg2pct','team2_fg3pct','team2_ftpct','team2_blockpct','team2_oppfg2pct','team2_oppfg3pct','team2_oppftpct','team2_oppblockpct','team2_f3grate','team2_oppf3grate','team2_arate',\n",
    "             'team2_opparate','team2_stlrate','team2_oppstlrate','team1_tempo','team1_adjtempo','team1_oe','team1_adjoe','team1_de','team1_adjde','team2_tempo','team2_adjtempo','team2_oe','team2_adjoe','team2_de','team2_adjde']\n",
    "#df_std : standardize dataset\n",
    "df_std = dfsample3.copy()\n",
    "df_std[nvar_list] = (dfsample3[nvar_list] - dfsample3[nvar_list].mean())/dfsample3[nvar_list].std()\n",
    "\n",
    "df4heatmaps = df_std\n",
    "# Compute the correlation matrix \n",
    "#corr = df4heatmaps.corr()\n",
    "# Print the correlation matrix\n",
    "#print(corr)\n",
    "# Draw the heatmap\n",
    "#sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Analysis - Eliminating Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "team1_pt_school_ncaa team1_pt_school_s16\n",
      "team1_pt_school_ncaa team1_pt_overall_s16\n",
      "team1_pt_school_ncaa team1_pt_school_ff\n",
      "team1_pt_school_ncaa team1_pt_career_school_wins\n",
      "team1_pt_overall_ncaa team1_pt_overall_s16\n",
      "team1_pt_overall_ncaa team1_pt_career_overall_wins\n",
      "team1_pt_school_s16 team1_pt_overall_s16\n",
      "team1_pt_school_s16 team1_pt_school_ff\n",
      "team1_pt_school_s16 team1_pt_career_school_wins\n",
      "team1_pt_overall_s16 team1_pt_overall_ff\n",
      "team1_pt_overall_s16 team1_pt_career_overall_wins\n",
      "team1_pt_school_ff team1_pt_overall_ff\n",
      "team1_pt_career_school_wins team1_pt_career_school_losses\n",
      "team1_pt_career_overall_wins team1_pt_career_overall_losses\n",
      "team2_pt_school_ncaa team2_pt_overall_ncaa\n",
      "team2_pt_school_ncaa team2_pt_school_s16\n",
      "team2_pt_school_ncaa team2_pt_overall_s16\n",
      "team2_pt_school_ncaa team2_pt_career_school_wins\n",
      "team2_pt_overall_ncaa team2_pt_school_s16\n",
      "team2_pt_overall_ncaa team2_pt_overall_s16\n",
      "team2_pt_overall_ncaa team2_pt_career_overall_wins\n",
      "team2_pt_school_s16 team2_pt_overall_s16\n",
      "team2_pt_school_s16 team2_pt_school_ff\n",
      "team2_pt_school_s16 team2_pt_career_school_wins\n",
      "team2_pt_overall_s16 team2_pt_school_ff\n",
      "team2_pt_overall_s16 team2_pt_overall_ff\n",
      "team2_pt_overall_s16 team2_pt_career_overall_wins\n",
      "team2_pt_school_ff team2_pt_overall_ff\n",
      "team2_pt_career_school_wins team2_pt_career_school_losses\n",
      "team2_pt_career_overall_wins team2_pt_career_overall_losses\n",
      "team1_tempo team1_adjtempo\n",
      "team1_oe team1_adjoe\n",
      "team2_tempo team2_adjtempo\n",
      "team2_oe team2_adjoe\n"
     ]
    }
   ],
   "source": [
    "dfsample4 = dfsample3.copy()\n",
    "attri_todrop = ['game_id']\n",
    "dfsample4 = dfsample3.drop(columns=attri_todrop)\n",
    "column_list = dfsample4.columns\n",
    "for i in range(0,len(column_list)-1):\n",
    "    for j in range(i+1,len(column_list)):\n",
    "        col_cor = dfsample4[column_list[i]].corr(dfsample4[column_list[j]])\n",
    "        if col_cor>=0.8:\n",
    "            print(column_list[i],column_list[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['team1_id', 'team2_id', 'game_id', 'team1_pt_overall_ncaa',\n",
       "       'team1_pt_career_school_wins', 'team1_pt_career_overall_wins',\n",
       "       'team1_pt_career_overall_losses', 'team1_pt_team_season_wins',\n",
       "       'team1_pt_team_season_losses', 'team1_pt_coach_season_wins',\n",
       "       'team1_pt_coach_season_losses', 'team2_pt_overall_ncaa',\n",
       "       'team2_pt_career_school_wins', 'team2_pt_career_overall_wins',\n",
       "       'team2_pt_career_overall_losses', 'team2_pt_team_season_wins',\n",
       "       'team2_pt_team_season_losses', 'team2_pt_coach_season_wins',\n",
       "       'team2_pt_coach_season_losses', 'team1_fg2pct', 'team1_fg3pct',\n",
       "       'team1_ftpct', 'team1_blockpct', 'team1_oppfg2pct', 'team1_oppfg3pct',\n",
       "       'team1_oppftpct', 'team1_oppblockpct', 'team1_f3grate',\n",
       "       'team1_oppf3grate', 'team1_arate', 'team1_opparate', 'team1_stlrate',\n",
       "       'team1_oppstlrate', 'team2_fg2pct', 'team2_fg3pct', 'team2_ftpct',\n",
       "       'team2_blockpct', 'team2_oppfg2pct', 'team2_oppfg3pct',\n",
       "       'team2_oppftpct', 'team2_oppblockpct', 'team2_f3grate',\n",
       "       'team2_oppf3grate', 'team2_arate', 'team2_opparate', 'team2_stlrate',\n",
       "       'team2_oppstlrate', 'team1_tempo', 'team1_adjtempo', 'team1_oe',\n",
       "       'team1_adjoe', 'team1_de', 'team1_adjde', 'team2_tempo',\n",
       "       'team2_adjtempo', 'team2_oe', 'team2_adjoe', 'team2_de', 'team2_adjde'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highly_corr = ['team1_pt_school_ncaa','team1_pt_school_s16','team1_pt_overall_s16','team1_pt_career_school_losses','team1_pt_school_ff','team1_pt_overall_ff',\n",
    "               'team2_pt_school_ncaa','team2_pt_school_s16','team2_pt_overall_s16','team2_pt_career_school_losses','team2_pt_school_ff','team2_pt_overall_ff']\n",
    "dataframe_1 = dfsample3.copy()\n",
    "dataframe_1 = dfsample3.drop(columns = highly_corr)\n",
    "dataframe_1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEaCAYAAAD3+OukAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA/pElEQVR4nO3deXQUVfr/8Xd1miwQyNbZA2gIi9GwI4tiEOKoIJBRxGFTQEUBRQT5wSCScVQGBAZFgiAGWXRQFIzMiMsEJCDIl02GJYCCIMiWdFYCCaG76/dHQ0skCUVIp7uS53VOjt3V1VWfzsE8feveuldRVVVFCCFErWRwdQAhhBCuI0VACCFqMSkCQghRi0kREEKIWkyKgBBC1GJSBIQQohaTIiCETiiKwocffujqGKKGkSIgdKWoqIhXXnmFpk2b4uPjQ1BQEB06dGDu3LmujnZThg4diqIoKIqC0WikcePGPPvss2RnZ1f6mN9//z2KonDs2LGqCypqHKOrAwhxI0aOHMl3333H22+/TatWrSgoKODHH3/k+PHjlT5mSUkJnp6eVZiycrp27crKlSuxWCzs3LmTp556ihMnTvDll1+6OpqoyVQhdMTPz0995513rrvfxx9/rLZt21b18vJSAwMD1QceeEDNyclRVVVV4+Pj1eHDh6tTpkxRw8LCVJPJpKqqqv7888/qww8/rPr5+an+/v7qfffdp+7Zs6fUcXfs2KHed999ar169VSTyaT++c9/Vo8dO+Z4PSkpSW3SpImampqqNm/eXK1bt67arVs39fDhwxXmfeKJJ9QePXqU2vb666+rBoNBvXDhgqqqqgqoy5cvd7x+6tQp9bHHHlP9/PxUb29vNT4+Xt2+fbuqqqp69OhRFSj1Ex8ff93fm6h95HKQ0JXw8HC+/vprcnJyyt3ngw8+YPDgwSQmJrJr1y6+++47HnjgAaxWq2OflStXkpWVxbp161i/fj1nz57l7rvvJiQkhE2bNrF161aaN29Ot27dyMrKAiAjI4P4+Hg6d+7Mjh07WL9+PR4eHtx3330UFxc7jn369GneffddPvroI7Zs2UJeXh7Dhw+/4c/q4+ODzWbDYrFc85qqqiQmJnLw4EH+85//sG3bNkJDQ7nvvvswm800bNiQL774AoBt27Zx+vRpVq9efcMZRC3g6iokxI34/vvv1UaNGqkGg0GNi4tTn376aTU1NVW12WyOfRo2bKiOHj263GPEx8erTZs2Va1Wq2NbUlKS2rFjx1L72Ww2NTo6Wp0zZ46qqvZv64899lipfYqLi1UfHx/1888/dxzHw8NDzczMdOyzYsUKVVEUtaioqNxMf2wJ7N+/X42Oji6ViataAmlpaSqg7t+/v1SWsLAw9dVXX1VVVVU3bdqkAurRo0fLPa8Q0icgdOWuu+7iyJEjbNu2jR9++IGNGzfyyCOP8OCDD7JmzRqysrI4ceIEf/rTnyo8Trt27TAYfm8Ib9++nZ07d+Lr61tqv6KiIn7++WfHPocPH75mn+LiYsc+ABEREQQHBzueR0ZGoqoqmZmZNGrUqNxMGzZswNfXF6vVysWLF+nRowcLFy4sc9/9+/cTFBREbGysY5uXlxcdO3Zk//79FX52Ia4mRUDojtFopEuXLnTp0oXx48fz4YcfMmTIEDZu3Mhtt90G2IdTVqRevXqlnttsNnr06MG8efOu2dfPz8+xz5AhQ5g0adI1+wQFBTke/7GT+UoWm81WYaaOHTuydOlSjEYj4eHheHl5Vbh/WZ9RVdXrfnYhriZFQOjelT/8mZmZxMfHExUVxTfffEPv3r01H6N9+/YsWbKEyMhIfHx8yt1nz549NGnSxCl/aH18fIiJidG07+23347ZbCYjI8PRGrh48SLbtm1j1KhRwO/F6Oq+ECH+SDqGha7Ex8ezYMECduzYwa+//sq6desYNWoU/v7+3HvvvQAkJSWxcOFCXnvtNQ4cOMD+/fuZN28eZrO53OM+99xzWK1WEhMT2bRpE8eOHeP777/n5ZdfZsuWLQBMnjyZAwcOMHjwYLZt28bRo0f57rvveOGFF/jll1+q5fNf0b17d+68804GDhzI5s2b2bdvH48//jjFxcWMHDkSgMaNG2MwGFi7di2ZmZnk5+dXa0ahD1IEhK48+OCDfPTRR/Ts2ZPmzZszbNgwmjZtyubNmzGZTAA89dRTLFmyhM8++4zWrVtzzz338NVXX2E0lt/wDQ0N5YcffsBkMvHwww/TvHlzBg0axK+//kp4eDhgb3Fs2bKFwsJC7r//fmJjY3n66acpKirC39+/Oj6+g6IopKam0qJFC3r16kWHDh04c+YM//3vfx2/h9DQUP7xj38wffp0wsPD6du3b7VmFPqgqKqsLCaEELWVtASEEKIWkyIghBC1mBQBIYSoxaQICCFELSZFQAghajFd3ix26tQpV0coxWQyVTgG3Z3oKSvoK6+esoK+8uopK7hn3oiIiDK3S0tACCFqMSkCQghRi0kREEKIWkyKgBBC1GJSBIQQohaTIiCEELWYFAEhhKjFak0RUH85hO3rVa6OIYQQbkXzzWLnzp3jxx9/JDc3l759+5KTk4OqqqWW1bsem83GpEmTCAwMZNKkSRQWFjJnzhyysrIIDg7mxRdfvGb91qqibt2A+t2X2PyDMHTq5pRzCCGE3mhqCWRkZDB27Fg2bdrEqlX2b9Nnzpxh0aJFN3SytWvXEhkZ6XiemppKXFwcc+fOJS4ujtTU1Bs63o1Q+j8JzeNQl76D+sshp51HCCH0RFMRWLJkCWPHjuXll1/Gw8MDgJiYGI4cOaL5RNnZ2ezatYsePXo4tm3fvp34+HjAvmzg9u3bbyT7DVGMRgzPToSAIGzzp6HmZDntXEIIoReaikBWVhZxcXGlthmNxhtawHrJkiUMHjy41ALd+fn5BAQEABAQEEBBQYHm41WG4tsAw+gpcLEYW/IbqBeLnXo+IYRwd5r6BKKioti9ezetW7d2bNu7dy+NGjXSdJKdO3fi5+dHdHQ0+/fvv+GQaWlppKWlATB9+nTHGqqVYjJx8aXXyHtjAnU+ehe/l15DMdxc/7jRaLy5TNVIT1lBX3n1lBX0lVdPWUFfeTUVgSFDhjBjxgzatGlDSUkJ7733Hjt37mTChAmaTnLo0CF27NjBjz/+SElJCUVFRcydOxc/Pz9yc3MJCAggNzeXBg0alPn+hIQEEhISHM9vena+xs1Q+g3l4qcfkLUkGUOfATd1OHecMbA8esoK+sqrp6ygr7x6ygrumbe8WUQ1FYFmzZoxc+ZMNm3ahLe3NyaTiWnTpmkeGTRw4EAGDhwIwP79+/n3v//NmDFjWL58Oenp6SQmJpKenk6HDh00fpybp9yXCCePo/57BWpEQ5T2d1fbuYUQwl1oKgKXLl2iQYMG9O3b17HNYrFw6dIl6tSpU+mTJyYmMmfOHNavX4/JZGLcuHGVPtaNUhQFBo9CPXsS2wdvYQgOQ2kcU23nF0IId6Coqqpeb6ekpCQGDRpEs2bNHNt++ukn/vWvf/G3v/3NmfnKVJWLyqgFedjeGA82G4aXZ6P4B97wMdyx6VcePWUFfeXVU1bQV149ZQX3zHtTi8ocP36cpk2bltoWExPDr7/+evPJXExp4I/huSlQdN4+dLTkoqsjCSFEtdFUBOrWrUt+fn6pbfn5+Xh5eTklVHVTGt6K4clxcPQn1GXz0NA4EkKIGkFTEejYsSNvv/02x48f5+LFixw/fpx58+bRuXNnZ+erNkqbTiiJg1H/Lx1V5hgSQtQSmjqG//KXv7Bs2TImT57MpUuX8PT0pFu3bgwYcHNDK92N0vNROHUc9fPlqOFRKK07uTqSEEI4laYi4OnpyVNPPcWTTz7JuXPnqF+/fqk7f2sKRVHgiedRM09je/+fGCbNQIm61dWxhBDCaTTfKnvhwgWOHDnC8ePH2b9/P/v27WPfvn3OzOYSiqcXhtEvg089bPPeQC3Ic3UkIYRwGk0tgQ0bNpCSkoK3tzeenp6O7YqiMG/ePKeFcxXFPxDDcy9je3MStnenYxj3GspN3A8hhBDuSlMRWLFiBePGjaNNmzbOzuM2lMYxKEPHor73JupH8+GJMTXyEpgQonbTVARsNhutWrVydha3Y+hwN7ZTx1H/8zFENEb5U6KrIwkhRJXS1CfQt29fVq1ahc1mc3Yet6P0/gu07YL62RLUvTtcHUcIIaqUppbAl19+SV5eHmvWrLlm+cd3333XKcHchWIwYBg+1t4/sGgWhklvokRom0JbCCHcnaYi8Pzzzzs7h1tTvLwxjH4Z2xvjsc17HcPkWSi+ZU97LYQQeqKpCMTGxjo7h9tTAoMxjJqMbdbL2BbMwDD2VRSjpl+fEEK4Lc1/xY4dO8aBAwc4d+5cqbl1HnvsMacEc0dKkxYojz+HungO6sfvwaCRMmJICKFrmopAWloaS5cupWXLlo5lJvfs2UP79u2dnc/tGDrfax8x9PUqiGyMcm8vV0cSQohK0zQ66IsvvmDy5MlMmDABT09PJkyYwLhx4/Dw8HB2Prek/HkItLoT9eNFqBm7XR1HCCEqTVNLoKCggNtuuw2w3yVss9lo06YNc+fO1XSSkpISkpKSsFgsWK1WOnXqRP/+/Vm5ciXr1q1zrC08YMAA2rZtW8mPUn0UgwHDU+OwTZ+IbeEMLE2agVddV8cSQogbpqkIBAYGkpmZSUhICOHh4ezYsYP69etj1NgxWqdOHZKSkvD29sZisTB16lRat24NQK9evejTp0+lP4CrKN51MTw3BdtrYyn8+H14YoyrIwkhxA3T9Fe8b9++nDx5kpCQEPr168c///lPLBYLw4YN03QSRVHw9vYGwGq1YrVaa0SHqmIKhaa3Yz3+i6ujCCFEpWhaY/iPLBYLFovF8YddC5vNxsSJEzlz5gz3338/gwcPZuXKlaSnp+Pj40N0dDSPP/74NTejgb1jOi0tDYDp06dTUlJyo5Gd5tzSZC58+SkhK9ah6KCPxGg0YrFYXB1DMz3l1VNW0FdePWUF98x79eSfVyu3CKiq6vi2XtF0EQaD5tmoATh//jyzZs1i2LBhNGjQwNEf8Mknn5Cbm8uoUaOue4yqXGj+Ztk2fYu6bB6Gae+hBIe5Os51ueMC2BXRU149ZQV95dVTVnDPvOUtNF/u5aChQ4eydOlSgApXEPvkk09uKEi9evWIjY1l9+7dpfoCevTowYwZM27oWO5ACY9CBTjzG+igCAghxNXKLQKzZ892PL7ZNQMKCgrw8PCgXr16lJSUsHfvXvr27Utubi4BAQEAbNu2jYYNG97UeVwiNAoA9cxJlLjad9+EEELfyi0CJpMJsF8KSk5O5uWXX6ZOJRdWyc3NJTk5GZvNhqqqdO7cmXbt2vHOO+9w7NgxFEUhODiYESNGVO5TuJBSvwFKfT97S0AIIXTmuqODDAYDmZmZVKL/2KFx48a8+eab12yvKRPTGSMbcenMSVfHEEKIG6apV7dfv34sWrSIrKwsbDZbqR8BHpGNpSUghNAlTfcJLFy4EICNGzde89qNdgzXRMbIRrAuD/VCIUrda4e4CiGEu9JUBGriYvJVySOysf3BmZMQ3dy1YYQQ4gZoKgLBwcHOzqFrxkj7SmPqmZMoUgSEEDqieT2BHTt2kJGRQUFBQantzz33XJWH0huP0Ejw8JB+ASGE7mjqGP7000957733sNlsbN26FV9fX/73v/9Rt67MnAnYVxgLDkM9KyOEhBD6oqkl8N133zFlyhQaNWrEhg0bGDp0KHfffTerVq1ydj79CIuC09ISEELoi6aWwPnz52nUyH7d+8rESDExMWRkZDg1nJ4ooZGQdRrVanV1FCGE0ExTSyAsLIwTJ07QsGFDGjZsyLfffouvr2+ZM37WWuFRYLFA9lkIKXuiJiGEcDeaisBjjz3GuXPnABg0aBBvv/02xcXFPPXUU04NpydK2JWJ5E5KERBC6EaFReCvf/0r3bp146677nJ864+JieGdd96plnC6EhYJgHrmN5SWHVwcRgghtKmwCHTt2pUNGzawbNky2rRpQ7du3WjTpk2tXWC+Ikq9+lDfz94SEEIInaiwCPTs2ZOePXvy22+/sXHjRhYvXkxJSQldunShW7duREdHV1dOfQiNRJV7BYQQOqJpdFBUVBQDBw4kOTmZsWPHUlxczN///nfGjx/v7Hy6ooRHSUtACKErN7Q25JUF4z09PfHw8HCrtX7dQmgknMtHPV/o6iRCCKGJptFBZrOZjRs3snHjRvLy8ujUqRPjx48nNjZW00lKSkpISkrCYrFgtVrp1KkT/fv3p7CwkDlz5pCVlUVwcDAvvviiroed/j5C6Ddo0sLVcYQQ4roqLAIbNmwgPT2dgwcPcvvtt/PII4/QsWPHcletL0+dOnVISkrC29sbi8XC1KlTad26Ndu2bSMuLo7ExERSU1NJTU1l8ODBN/WBXMoxQugkihQBIYQOVHg56IsvvqBVq1YkJyczZcoUunbtesMFAH6/jARgtVqxWq0oisL27duJj48HID4+nu3bt1fiI7gRUyh4GOGsdA4LIfShwpbAnDlzquxENpuNiRMncubMGe6//36aNm1Kfn6+Y6H5gICAa2YovSItLY20tDQApk+f7lj/2F0YjUZHJnN4FMacLPzdLOMVV2fVAz3l1VNW0FdePWUFfeXVPJX0zTIYDMycOZPz588za9Ysjh8/rvm9CQkJJCQkOJ6bzWZnRKw0k8nkyGQNDsN6/KjbZbzi6qx6oKe8esoK+sqrp6zgnnkjIsqeyeCGRgdVhXr16hEbG8vu3bvx8/MjNzcXgNzcXBo0aFDdcaqcEhYJmTKRnBBCH6qlCBQUFHD+/HnAPlJo7969REZG0r59e9LT0wFIT0+nQ4caMN1CWBRYLWA+6+okQghxXdVyOSg3N5fk5GRsNhuqqtK5c2fatWtHs2bNmDNnDuvXr8dkMjFu3LjqiONUSmjk78NEQ2UiOSGEeyu3CIwcOVLTAd59993r7tO4cWPefPPNa7bXr1+fqVOnajqPboRFAZeHibZycRYhhLiOcovA888/73h8+PBh0tPTefDBBwkODiYrK4tvvvmGe+65p1pC6olSz/fyRHIyTFQI4f7KLQJX3w2ckpLCyy+/TGBgoGNbmzZtmDZtGr1793ZuQj0Kj0KVOYSEEDqgqWM4JyfHcbPXFd7e3uTk5DgllN4poZHSEhBC6IKmjuH27dszY8YMHnnkEQIDA8nOziY1NZV27do5O58+hUVBYQFqYQGKr/6HvQohai5NReDpp5/m008/ZdGiReTk5BAYGEinTp149NFHnZ1Pl5SwyN+XmoyRIiCEcF+aioCnpyeDBg1i0KBBzs5TMzhGCP2GEnObi8MIIUT5NN8nsGfPHjZv3kx+fj6TJk3iyJEjFBUVcccddzgznz6ZQsBolAVmhBBuT1PH8FdffcWiRYsIDw/nwIEDgL118PHHHzs1nF4pBg8IiZClJoUQbk9TEVi7di2vvPIKiYmJGAz2t0RGRnLq1CmnhtO1sEg4Ky0BIYR701QEioqKrpkW1WKxYDRW2ySkuqOERUHWGVSLxdVRhBCiXJqKwG233UZqamqpbV999RW33367MzLVDKGRYLWC+YyrkwghRLk0FYHhw4ezbds2Ro8eTXFxMS+88AJbt27liSeecHY+3VLC7SOE5KYxIYQ703Q9JyAggH/84x8cPnwYs9lMUFAQMTExjv4BUYbQq9YbdnEUIYQoj+aL+oqi0LRpU5o0aeLYZrPZpBCUQ6lbD/wCpCUghHBrmorAL7/8QkpKCsePH6ekpKTUa5988olTgtUIoZEykZwQwq1pKgLJycm0a9eOkSNH4uXldcMnMZvNJCcnk5eXh6IoJCQk0LNnT1auXMm6descy0oOGDCAtm3b3vDx3ZUSFoW6c7OrYwghRLk0FQGz2cyAAQNQlMpd3fbw8GDIkCFER0dTVFTEpEmTaNmyJQC9evWiT58+lTqu2wuLhPPnUM8VoNSXOYSEEO5H0wX9Dh068L///a/SJwkICCA6OhoAHx8fIiMja8U01EqYjBASQrg3TS2BS5cuMWvWLFq0aIG/v3+p15577rkbOmFmZiZHjx4lJiaGgwcP8s0337Bx40aio6N5/PHH8fX1veY9aWlppKWlATB9+vRrblxzNaPRWGYmy213kA34ns/Hx00yl5fVXekpr56ygr7y6ikr6Cuvoqqqer2dPv3003Jfu5HppIuLi0lKSuLhhx+mY8eO5OXlOfoDPvnkE3Jzcxk1atR1j+Nu01WYTCbMZvM121WbFdvo/ijdH8Lw6DAXJLtWeVndlZ7y6ikr6CuvnrKCe+aNiIgoc7umlkBVrBtgsViYPXs2Xbt2pWPHjgClWhU9evRgxowZN30ed6IYPCA0AlXmEBJCuKlyi0BGRoZjneF9+/aVewAtU0mrqsqCBQuIjIzkoYcecmzPzc0lICAAgG3bttGwYUPNwXUjLBJOHHN1CiGEKFO5RSAlJYXZs2cD8O6775a5j6IozJs377onOXToEBs3bqRRo0ZMmDABsA8H3bx5M8eOHUNRFIKDgxkxYkRlPoNbU0KjUH/cimq5hGKs4+o4QghRSrlF4EoBAPt9AjejRYsWrFy58prtNemegHKFR4LNBllnILwGtnSEELomcz44mRJ6ZZio9AsIIdyPpo7hCxcu8Omnn5KRkcG5c+e4ekBReZeKxGVhVyaS+00mkhNCuB1NLYH333+fo0eP0q9fPwoLCxk+fDgmk4levXo5O5/uKT51wS9QWgJCCLekqQjs2bOH8ePH06FDBwwGAx06dODFF19k06ZNzs5XM4RFynrDQgi3pKkIqKpK3bp1AfD29ub8+fP4+/tz5oysmqWFEhYJZ06i4b48IYSoVpr6BBo3bkxGRgZxcXG0aNGClJQUvL29CQ8Pd3a+miEsCi4Uwrl8aODv6jRCCOGgqSXwzDPPEBwcDNiXmvT09OT8+fM3PG9QbfX7RHLSLyCEcC+aWgKhoaGOxw0aNODZZ591WqAa6eoRQs1ud3EYIYT4XblFYP369ZoO0L179yoLU2MFBkMdT5A5hIQQbqbcIqB15I8UgetTDAb7RHKnZYSQEMK9lFsEkpKSqjNHjaeERaEeP+LqGEIIUYqmPgGA8+fPs2vXLsfMn23btqVevXrOzFazhEXCzi2oly6h1JGJ5IQQ7kHT6KB9+/YxevRovvrqKw4fPszXX3/N6NGj2bt3r7Pz1RxhUaDaIPO0q5MIIYSDppZASkoKI0aMoEuXLo5tP/zwAykpKbz11lvOylajKGGRqABnf4PIRq6OI4QQgMaWQG5uLp06dSq17c477yQvL88ZmWqm0MvDRKVzWAjhRjQVgXvuuYevv/661LZvv/2We+65xymhaiLF2wf8g2SYqBDCrWi6HHT06FH++9//smbNGgIDA8nJySE/P5+mTZuWGkX06quvlvl+s9lMcnIyeXl5KIpCQkICPXv2pLCwkDlz5pCVlUVwcDAvvvgivr6+VfPJ3FF4FKrcNSyEcCOaikCPHj3o0aNHpU/i4eHBkCFDiI6OpqioiEmTJtGyZUs2bNhAXFwciYmJpKamkpqayuDBgyt9HnenhEai/l86qqqiKLK6gBDC9TQVgW7dut3USQICAhwLyvv4+BAZGUlOTg7bt2/nb3/7GwDx8fH87W9/q9FFgLAoKDoPBXngF+DqNEIIoa0ILFiwgGHDhuHl5eXYlpuby/z583n55Zdv6ISZmZkcPXqUmJgY8vPzHcUhICCAgoKCMt+TlpZGWloaANOnT8dkMt3QOZ3NaDRqynSx+W3kAX5FhXg2aer0XGXRmtVd6CmvnrKCvvLqKSvoK6+mIlBUVMRLL73E888/T7Nmzdi8eTOLFy++4UtExcXFzJ49m6FDhzrWJ9AiISGBhIQEx3Oz2XxD53U2k8mkKZPq0wCAvEP7MYS5ZtF5rVndhZ7y6ikr6CuvnrKCe+aNiIgoc7umInBlFbE333yTiIgIcnNzmTBhAi1atNAcwGKxMHv2bLp27UrHjh0B8PPzc9yBnJubS4MGDTQfT5cCgsDTU6aUFkK4DU1DRAECAwOpU6cOZ8+eJSQkhLCwMM0nUVWVBQsWEBkZyUMPPeTY3r59e9LT0wFIT0+nQ4cONxBdf+wTyclSk0II96GpJbBs2TI2bdrE008/Tdu2bVmxYgUvvfQSTz75JJ07d77u+w8dOsTGjRtp1KgREyZMAGDAgAEkJiYyZ84c1q9fj8lkYty4cTf3aXRACYtCPfazq2MIIQSgsQicPHmSmTNn4u/vD8CQIUNo164dycnJmopAixYtWLlyZZmvTZ06VXvamiAsEnZ8j3qpBKWOp6vTCCFqOU2Xg/761786CsAVsbGxzJo1yxmZarbQSFBVmUhOCOEWKiwCa9asKfV8z549pZ6X9+1elE8Jv7LesPQLCCFcr8IisGrVqlLP58yZU+q51iUoxVWuTCQnI4SEEG6gwiKgqmqFb77e6+Jaipc3BJqkJSCEcAsVFoHrzW8j899UUmiktASEEG6hwtFBqqqSmZnp+MZf1nNx45SwKNQf1stEckIIl6uwCFy8eJHnn3++1LY/PheVEBYJxUWQnwv+ga5OI4SoxSosAp988kl15ahVlLAo+1KTZ36TIiCEcCnN00aIKhQmI4SEEO5BioAr+AeBl7eMEBJCuJwUARewTyQXgSrrDQshXKzcInDs2LFqjFH7KGFRcFpaAkII1yq3CFy9gPyYMWOqJUytEhoJOVmoJRddnUQIUYuVOzqobt267Ny5k6ioKHJzc0vdH3C10NBQpwasscKjLk8kdwqibnV1GiFELVVuERg2bBhLlizBbDZjs9nKvT9AhpFWjhIaeXmY6EkpAkIIlym3CNx5553ceeedADz++OMsW7as0ieZP38+u3btws/Pj9mzZwP2GUjXrVvnWFJywIABtG3bttLn0B3HRHK/IfcMCyFcRdOiMosXLwbAZrORn5+Pn58fBoP2gUXdunXjgQceIDk5udT2Xr160adPnxuIW3MoXl4QGCzrDQshXEpTEbh06RILFixg8+bN2Gw2PDw86NKlC8OHD6du3brXfX9sbCyZmZk3HbbGCYuSG8aEEC6luSVQXFzM7NmzCQ4OJisri48//pjFixfz3HPPVfrk33zzDRs3biQ6OprHH38cX1/fMvdLS0sjLS0NgOnTp2MymSp9TmcwGo2VylRwaxOK160lKCio2iaSq2xWV9FTXj1lBX3l1VNW0FdeTUVg9+7dzJs3Dy8vLwAiIiIYNWrUTU0m96c//Yl+/foB9s7lZcuWMWrUqDL3TUhIICEhwfHcbDZX+rzOYDKZKpXJ5mdCLb6A+fBPKAFBTkh2rcpmdRU95dVTVtBXXj1lBffMGxERUeZ2TRf2PT09KSgoKLWtoKAAo1FTDSmTv78/BoMBg8FAjx49OHLkSKWPpVfK5TmEZPoIIYSraPor3r17d15//XV69erluBz05Zdflvp2fqNyc3MJCAgAYNu2bTRs2LDSx9KtMPt6w+qZkyi3tXJxGCFEbaSpCDz88MMEBASwefNmcnJyCAwMpG/fvtx7772aTvLWW2+RkZHBuXPnePbZZ+nfvz/79+/n2LFjKIpCcHAwI0aMuKkPokv+geDlIy0BIYTLaCoCiqLQvXt3unfvXqmTjB079pptlT1WTaIoCoTJUpNCCNeRWURdTAmNlJaAEMJlpAi4WvjlieQuykRyQojqJ0XAxZTLncPI2gJCCBeQIuBqV5aalCIghHABzdNGfPbZZ2zevJlz586xdOlS/ve//3H69GkeeOABZ2es2UIiQFFkgRkhhEtoagksXbqUEydOMGbMGMf0Bg0bNuTbb791arjaQPG8PJGctASEEC6gqSWwbds25s6di7e3t6MIBAYGkpOT49RwtUZ4FKqMEBJCuICmloDRaMRms5XaVlBQQP369Z0SqraxDxM9ifqH37EQQjibpiLQqVMn5s2b55gOOjc3l5SUFLp06eLUcLVGWBSUXIS8bFcnEULUMpqKwMCBAwkJCWH8+PFcuHCBMWPGEBAQwKOPPursfLXC7xPJSb+AEKJ6aeoTMBqNDB06lKFDhzouA1XX/Pe1gmMiud9QYlu7NosQolbRVATOnj1b6nlRUREAderUcUwJLW6CXwB4+0hLQAhR7TQVgTFjxpT7msFgoF27djz11FP4+/tXVa5axT6RnIwQEkJUP01F4JlnniEjI4N+/fo5Vsz57LPPaN68ObGxsXz00UekpKQwfvx4Z+etsZSwSNSf9rk6hhCiltF0HWflypWMGDGCsLAwjEYjYWFhPP3006xatYrIyEhGjRpFRkaGs7PWbGFRkGNGvVjs6iRCiFpEU0tAVVWysrKIjIx0bDObzY57B7y9vbFareW+f/78+ezatQs/Pz9mz54NQGFhIXPmzCErK4vg4GBefPHFchearw2UsEhUsN853KiJq+MIIWoJTUWgZ8+e/P3vf6dbt24EBQWRk5PDd999R8+ePQHYtWsXzZo1K/f93bp144EHHiA5OdmxLTU1lbi4OBITE0lNTSU1NZXBgwff5MfRsSsjhE7/hiJFQAhRTTRdDurbty8jR44kLy+PHTt2kJOTw8iRI0lMTATgzjvvZPLkyeW+PzY29ppv+du3byc+Ph6A+Ph4tm/fXsmPUEOEhNsnkpM5hIQQ1UhTSwCgdevWtG7duspOnJ+f71hoPiAggIKCgnL3TUtLIy0tDYDp06djMpmqLEdVMBqNVZLJHBKOMTcLfyd+vqrKWl30lFdPWUFfefWUFfSVV3MROHbsGAcOHODcuXOoqurY/thjjzkl2NUSEhJISEhwPDebzU4/5424MmLqZlmDw7H++otTP19VZa0uesqrp6ygr7x6ygrumTciIqLM7ZqKQFpaGkuXLqVly5bs3r2b1q1bs2fPHtq3b1/pQH5+fuTm5hIQEEBubi4NGjSo9LFqCiUsCvWnvag2G4rcgCeEqAaa/tJ88cUXTJ48mQkTJuDp6cmECRMYN24cHh4elT5x+/btSU9PByA9PZ0OHTpU+lg1RlgklJRArkwkJ4SoHpqKQEFBAbfddhtgv7vVZrPRpk0bdu7cqekkb731FlOmTOHUqVM8++yzrF+/nsTERPbs2cOYMWPYs2ePo5O5NnOsNyx3Dgshqommy0GBgYFkZmYSEhJCeHg4O3bsoH79+hiN2roUxo4dW+b2qVOnag5aK1xZb/jMSZTb27g4jBCiNtD0V7xv376cPHmSkJAQ+vXrxz//+U8sFgtDhw51crxapoE/+NSTloAQotpoKgLdunVzPG7Tpg0ffPABFosFb29vZ+WqlewTyUWiyr0CQohqoqlP4P/9v/9X6rnRaMTb25tJkyY5JVRtpoRFwmlpCQghqoemInDmzJlrtqmqes06A6IKhEZCXjZq8QVXJxFC1AIVXg6aN28eABaLxfH4iqysLBo2bOi8ZLWUEh51eSK5U9A4xtVxhBA1XIVFIDQ0tMzHiqLQvHlzOnfu7LxktVXoVRPJSREQQjhZhUXgykLyTZs2rdJ5g0QFQsJBMchEckKIaqFpdFDr1q05deoUx44do7i49KIn3bt3d0qw2kqpUwdMIdI5LISoFpqKwOrVq1m1ahWNGzfGy8ur1GtSBJwgLEqGiQohqoWmIrB27VqmTZtG48aNnZ1HcHmVsYN7ZCI5IYTTafoL4+npWWppSeFkYVFwqQRyslydRAhRw2kqAo899hiLFy8mNzcXm81W6kdUPeXKHEIZu1Ft5a/dLIQQN0vT5aD58+cDsG7dumte++STT6o2kYDIW8DLB3V5Murny1HuaAt3tEO5oy1KvfquTieEqEE0FYE/3igmnEup54thxvuo+3+EvTtQ9+2CrRtQFQM0aY5yRzuUlh0g6hb7fENCCFFJmopAcHAwADabrdTawMJ5lHr1Ue68B+68x35J6Nhh1L07UPfuRE39EDX1Q/APQolrhxLXHm5rieJd19WxhRA6o6kInD9/nvfff5+tW7diNBpZvnw5O3bs4PDhw/zlL3+5qQCjR4/G29sbg8GAh4cH06dPv6nj1USKwQOim6NEN4e+g1DzclD377IXhR3fo276FjyM0Ox2lLj2KHHtIDRSWglCiOvSVAQWLVpEvXr1mD9/PuPGjQOgWbNmLFu27KaLAEBSUpKsMXwDFP9AlLsS4K4EVIsFjhywF4Q9O1BXpqCuTIHgsN8LQvM4lDqero4thHBDmorA3r17WbhwYamVxBo0aEB+fr7TggltFKPR/ke+eRz0G4ZqPou6b6e9IHz/Ler6/4CnJ7RohRLXDstd3VENdVBuYn1oIUTNoakI1K1bl3PnzpXqCzCbzVXWN/DGG28AcN9995GQkFAlx6ytFFMoSree0K0naslF+GmfvSDs3YG6ZzvZHy2wz03kFwCBJpQAEwSYLj8Ouvw4GPz87ZehhBA1mqKqqnq9nVJTU9mxYwd/+ctfmDVrFpMnT2bFihW0b9+eXr163VSAnJwcAgMDyc/P5/XXX2fYsGHExsaW2ictLY20tDQApk+fTklJyU2ds6oZjUYsFourY1RIVVWsp45jPbiXS2dPYc3OxGbOxGrOxGo+CyUXS7/B4IEh0IRHUDAGUygephAMQSF4mELwCArBYArB4Bfo9BaFHn63V+gpK+grr56ygnvm9fQs+5KwpiKgqipr164lLS0Ns9mMyWQiISGBnj17Vmnn48qVK/H29qZPnz4V7nfq1KkqO2dVMJlMmM1mV8fQpKysqqrChULINUOOGTU3G3LMkJt11WOz/S7mq3l4gF8gBJrA189+acpotG/3qPP7Y6Ox7OeOx0YUY+nneNiPZWrZluzC89X4G6o8Pf07AH3l1VNWcM+8ERERZW7XdDlIURR69ep109/6/6i4uBhVVfHx8aG4uJg9e/bQr1+/Kj2HuD5FUaBefftP1K2UVdZVVYXz5+ByUVBzs656bIas06hWK1gt9h/L5R+rFayX7I8rUN43EXOgCR57Ctp0ltFOQjiBpiKQmprKHXfcQUzM74ucHD58mP3799O3b99Knzw/P59Zs2YBYLVaufvuu2XdAjelKAr4NrD/NCy7UFREVdXLBeGqomCxlC4af/xv0XkMX6/G8u50aHUnhgHPoAQFO+XzCVFbaZ5F9IEHHii1LSoqipkzZ95UEQgNDWXmzJmVfr/QD0VR7Jd6jEbA67r7XxGY0IusTz5A/eJf2JJGo/QdhNL9IRndJEQV0TSBnMViKTU8FOwdH+7WQStqHsXDiOFPf8bw6jxodgfqyhRs08ajHvvZ1dGEqBE0FYHo6Gi++eabUtu+/fZboqOjnRJKiD9STKEYnn8Fw7MTIT8P27QJ2D5ehFp0wdXRhNA1TZeDnnjiCV5//XU2btxIaGgoZ8+eJS8vj1deecXZ+YRwUBQF2t2F4bbWqKnLUdf/B3XnFgwDRqC07ezqeELo0nWLgKqqeHp68vbbb7Nz506ys7Pp2LEj7dq1w9vbuzoyClGKUrceysBnUTvdi215MrZ3/wGtO9qLQaB0HAtxI657OUhRFF566SU8PT2566676NOnD3fddZcUAOFySnRzDC//E6XfUMj4EdvU0djSvrAPVRVCaKKpT+CWW27h9OnTzs4ixA1TjEYM9z+M4dVke8fxJynYpr2E+uthV0cTQhc09QncfvvtTJs2jfj4eEwmU6nXunfv7pRgQtyIKx3H7NyM7eNF2N54CaV7L5TEQbLOghAV0FQEDh06REhICAcOHLjmNSkCwl0oigLt78YQ2wb188sdx7t+wDBwBErrTq6OJ4Rb0lQEkpKSnJ1DiCqj1K2HMuhZ1E7d7B3HydOgdScMA56WjmMh/kBTnwDAuXPn2LhxI2vWrAHss39mZ2c7LZgQN0tp0gLDlDkojzwBGbuwTX0OW9oa+3KdQghAY0sgIyOD2bNnEx0dzaFDh+jTpw9nzpxhzZo1TJo0ydkZhag0xWhEeeAR1HZ3YfvXAtRP3kf9Yb19EZ66vvZJ8+rWQ6nna39e1xcuP5apKURtoKkILFmyhLFjxxIXF8ewYcMAiImJ4ciRI04NJ0RVUYLDMIxJQt2xGXXNR6jpX5daQ6HMWUy9ff5QGOqh1Kt/eVu934vF5WJixYqqGmS2U6ErmopAVlYWcXFxpd9oNGKV8dhCRxRFQelwN3S4GwD10iUoKoTzl38uFKJeKITz5+3rK5w/d3nbefvrZ09dfr2w1NoKVwqIGcA/CKXZHdD8dvt/QyOlKAi3pqkIREVFsXv37lLTPO/du5dGjRo5K5cQTqfUqQN1AqDB78ukav1zrV4qcRQOLheOehcvUPjj/6Ee/B9sS7cXB78AlKa3Q7M77EUhoqEUBeFWNBWBIUOGMGPGDNq0aUNJSQnvvfceO3fuZMKECc7OJ4RbUup4gn+g/eeyuiYTF+6Mt6+dcPYU6k/77Gs8/7QfdnxvLwq+DaDZ7ShNL7cUom5BMWgenyFEldNUBJo1a8bMmTPZtGkT3t7emEwmpk2bRlBQkLPzCaE7iqJAWCRKWCTcc7+9KJjP2ovCoX2oP+1D3fWDvSjUrQdNb0dpdrkoNIyWDmlRrSosAhcvXmTVqlWcOHGCW2+9lT//+c/UqVOnSgPs3r2bDz74AJvNRo8ePUhMTKzS4wvhaoqiQHAYSnAY3JUAgJqdhfrzPvhpP+qhfaj/22YvCt4+EBOL0uwOlGa3Q+MY+9rNQjhJhf+6UlJSOHLkCG3atOH//u//KCwsZPjw4VV2cpvNRkpKClOmTCEoKIi//vWvtG/fnqioqCo7hxDuSAkKRgm6FzrdC4Cal22/bHT58pG6eqm9KHh6QUgEGKq+HyHb0xOrChjrgIcHeNhXflMu/xcPo2Nb2c89wKPOVY+N9oLlhD6P4gZ+qOcvlH3uip57eMjltuuosAjs3r2bGTNmEBAQwAMPPEBSUlKVFoHDhw8TFhZGaGgoAF26dGH79u1SBESto/gHodx5D9x5DwBqQR78nGG/dJSdWfUnVFUMRiMUXbCv6VxcYl//2XIJ1Wq5/NgClkuX14G2/r7+c0WHrfqkAOTfzJs9PP5QsC4XCWMdcFKBMBuNWC0V/64qwzBkNErT2Co95nUvBwUE2EdOmEwmLlyo2lWccnJySvUrBAUF8fPP1y4bmJaWRlpaGgDTp0+/ZhI7VzMajW6XqTx6ygr6ylulWU0miI6B+/tUzfHKYDQasdzgHypVVX8vFpZLYLGgWiyXH1+yT+OtVn0p8DAYsF4sth//yrkvWewF6w9Z7M8tvxe0S5d+z2i9ep9LYLVVeVYAxaBgtFX976FeaCh1qvj/hwqLgNVqZd++fY7nNput1HOAO+64o9InV8v4x1LW8LmEhAQSEhIcz81mc6XP6Qwmk8ntMpVHT1lBX3n1lBWqMq8BjF72HycxmUzk1MrfbWn5AJU8bkRERJnbKywCfn5+vPvuu47nvr6+pZ4risK8efMqFQjs3/yvnn8oOzvb0fIQQgjhfBUWgeTkZKeevEmTJpw+fZrMzEwCAwPZsmULY8aMceo5hRBC/M6lY888PDwYPnw4b7zxBjabjXvvvZeGDRu6MpIQQtQqLh+A3LZtW9q2bevqGEIIUSvJAFohhKjFpAgIIUQtJkVACCFqMSkCQghRiylqWXdsCSGEqBWkJVAF9LTOsp6ygr7y6ikr6CuvnrKCvvJKERBCiFpMioAQQtRiUgSqwNWT27k7PWUFfeXVU1bQV149ZQV95ZWOYSGEqMWkJSCEELWYFAEhhKjFXD6BnF6ZzWaSk5PJy8tDURQSEhLo2bOnq2Ndl81mY9KkSQQGBrr1MLbz58+zYMECTpw4gaIojBw5kmbNmrk6Vrn+85//sH79ehRFoWHDhowaNQpPT09Xx3KYP38+u3btws/Pj9mzZwNQWFjInDlzyMrKIjg4mBdffBFfX18XJy076/Lly9m5cydGo5HQ0FBGjRpFvXr1XJzUrqy8V6xZs4YPP/yQ999/nwYNGrgoYcWkJVBJHh4eDBkyhDlz5vDGG2/wzTff8Ntvv7k61nWtXbuWyMhIV8e4rg8++IDWrVvz1ltvMXPmTLfOnJOTw1dffcX06dOZPXs2NpuNLVu2uDpWKd26dWPy5MmltqWmphIXF8fcuXOJi4sjNTXVNeH+oKysLVu2ZPbs2cyaNYvw8HA+//xzF6W7Vll5wf5Fce/evW6/PKoUgUoKCAggOjoaAB8fHyIjI8nJyXFxqoplZ2eza9cuevTo4eooFbpw4QIHDhyge/fugH0tXHf51lcem81GSUkJVquVkpISt1shLzY29ppv+du3byc+Ph6A+Ph4tm/f7opo1ygra6tWrfDw8ACgWbNmbvX/Wll5AZYuXcqgQYPKXDLXncjloCqQmZnJ0aNHiYmJcXWUCi1ZsoTBgwdTVFTk6igVyszMpEGDBsyfP59ff/2V6Ohohg4dire3t6ujlSkwMJDevXszcuRIPD09adWqFa1atXJ1rOvKz893FKuAgAAKCgpcnEib9evX06VLF1fHqNCOHTsIDAzklltucXWU65KWwE0qLi5m9uzZDB06lLp167o6Trl27tyJn5+fo/XizqxWK0ePHuVPf/oTb775Jl5eXm5zqaIshYWFbN++neTkZBYuXEhxcTEbN250dawaafXq1Xh4eNC1a1dXRynXxYsXWb16NY899piro2giReAmWCwWZs+eTdeuXenYsaOr41To0KFD7Nixg9GjR/PWW2+xb98+5s6d6+pYZQoKCiIoKIimTZsC0KlTJ44ePeriVOXbu3cvISEhNGjQAKPRSMeOHfnpp59cHeu6/Pz8yM3NBSA3N9dtOy6v2LBhAzt37mTMmDFufYnl7NmzZGZmMmHCBEaPHk12djYTJ04kLy/P1dHKJJeDKklVVRYsWEBkZCQPPfSQq+Nc18CBAxk4cCAA+/fv59///jdjxoxxcaqy+fv7ExQUxKlTp4iIiGDv3r1ERUW5Ola5TCYTP//8MxcvXsTT05O9e/fSpEkTV8e6rvbt25Oenk5iYiLp6el06NDB1ZHKtXv3br744gteffVVvLy8XB2nQo0aNeL99993PB89ejT/+Mc/3LbIyh3DlXTw4EGmTp1Ko0aNHN9KBgwYoIv1kq8UAXceInrs2DEWLFiAxWIhJCSEUaNGucXwxfKsXLmSLVu24OHhwS233MKzzz5LnTp1XB3L4a233iIjI4Nz587h5+dH//796dChA3PmzMFsNmMymRg3bpxb/I7Lyvr5559jsVgc+Zo2bcqIESNcnNSurLxXBjWAFAEhhBBuTPoEhBCiFpMiIIQQtZgUASGEqMWkCAghRC0mRUAIIWoxKQLCLQwZMoSzZ8/e1DFWr17NggULqiRP//79OXPmTJUcSwh3JjeLCacYPXo0eXl5GAwGvL29adOmDcOHDy93/p/ly5ff9Dkffvjhmz6GVrt37+bzzz/n6NGj1KlTh6ioKHr37k379u2rLYMrjR49mmeeeYaWLVu6Ooq4SVIEhNNMnDiRli1bkpOTwxtvvMGqVasYNGhQqX2sVqtjdki92Lp1K++++y6PP/44EydOxNvbm4MHD7Jx48ZaUwREzSFFQDhdYGAgrVu35sSJE4D9Usvw4cNZu3YtVquV5ORk+vfvz9y5cwkLCyM5ORkvLy+ysrI4cOAAUVFRjBkzhrCwMABOnDjBkiVL+OWXXzAajTz44IM8/PDDrFy5kjNnzjBmzBgyMzN57rnnGDFiBJ9++imqqtK7d2969+4NwOHDh/nggw84efIknp6edOzYkSeeeAKjseL/JVRVZenSpTzyyCOlpuSOjY0lNjYWsE8r/fnnn7Nu3TpKSkpo3bo1w4cPp27duo5cI0eOZOXKlRQXFzNgwACio6NZsGABZrOZrl278uSTTwL2+XLWrVvHrbfeSnp6OgEBATz55JPExcUB9rUMFi1axMGDB/H19aVv376ORc5XrlzJb7/9hqenJ9u2bcNkMjF69GjHlBY5OTksXryYAwcO4O3tTa9evRwLI1X03nfeeQez2cyMGTMwGAz069ePvn37Vsm/FVH9pE9AOJ3ZbObHH38sNa3u9u3bmTZtGnPmzCnzPZs3b+bRRx/lgw8+ICwsjI8//hiAoqIiXnvtNVq3bs3ChQsdC6KUZ9++fbz99ttMmTKF1NRU9uzZA4DBYOCJJ54gJSWF119/nX379vHNN99c97OcOnWK7OxsOnXqVO4+GzZsYMOGDSQlJTFv3jyKi4tJSUkptc/PP//M22+/zdixY1m6dCmrV6/mlVde4Z///Cc//PADGRkZpfYNCQkhJSWF/v37M2vWLAoLCwF4++23CQoKYuHChYwfP54VK1awd+9ex3t37txJly5dWLJkCe3bt2fx4sWAvVDNmDGDW265hYULFzJ16lTWrl3L7t27r/ve559/HpPJxMSJE1m+fLkUAJ2TIiCcZubMmQwdOpSpU6cSGxtb6pr9n//8Z3x9fctdgrFjx47ExMTg4eHB3XffzbFjxwD7HyZ/f3969+6Np6cnPj4+jtlGy/Loo4/i7e1No0aNuPfee9m8eTMA0dHRNGvWDA8PD0JCQkhISCj1h7c8586dA+yT3JXn+++/56GHHiI0NBRvb28GDhzIli1bsFqtjn369evnWHvAy8uLu+++Gz8/PwIDA2nRokWpWVP9/Pzo1asXRqORLl26EBERwa5duzCbzRw8eJBBgwbh6enJLbfcQo8ePUpNY92iRQvatm2LwWDgnnvucfwejxw5QkFBAf369XMs2dijR49SK6KV915Rs8jlIOE0EyZMKLfjMCgoqML3Xv1H1svLi+LiYsC+OlpoaKjmDFefx2Qycfz4ccD+jX7ZsmUcOXLEsSKYlrUW6tevD0BeXh4hISFl7pObm0twcHCp81qtVvLz8x3b/Pz8HI89PT2veX7l84L9ctrVUycHBweTk5NDbm4uvr6++Pj4lDrXkSNHyj3PpUuXsFqtZGVlkZuby9ChQx2v22w2brvttuu+V299OKJiUgSES1R2PvigoCDHt3ktsrOzHesTm81mx0pa77//PrfccgsvvPACPj4+fPnll2zduvW6x4uIiCAoKIitW7fSp0+fMvcJCAggKyvL8dxsNuPh4YGfnx/Z2dmas1+Rk5ODqqqO35nZbKZ9+/YEBARQWFhIUVGRoxCYzWYCAwOve0yTyURISIjbrikhqo9cDhK60q5dO/Ly8vjyyy+5dOkSRUVF/Pzzz+Xuv2rVKi5evMiJEyfYsGGDY1nCoqIi6tati7e3NydPnuTbb7/VdH5FUXjiiSdYtWoV3333HRcuXMBms3Hw4EEWLlwIwF133cWXX35JZmYmxcXFrFixgs6dO1f6G3R+fj5fffUVFouFH374gZMnT9KmTRtMJhPNmzfnX//6FyUlJfz666989913mlbdiomJwcfHh9TUVEpKSrDZbBw/fpzDhw9ryuTv709mZmalPo9wL9ISELri4+PDlClTWLJkCZ999hlGo5FevXqV2y8QGxvLmDFjsNls9O7d27H275AhQ3jvvff44osvuPXWW+nSpQv79u3TlKFTp054e3uzevVqFi9ejKenJw0bNnS0DO69915yc3NJSkqipKSEVq1aMXz48Ep/5qZNm3L69GmefPJJ/P39GTdunOOy1AsvvMCiRYt45pln8PX15dFHH9U0dt9gMDBx4kSWLVvG6NGjsVgsREREaF4SMTExkcWLF/Phhx/y8MMPl9sqEu5P1hMQNdKVoZgrVqzQ9TXsK0NEX3vtNVdHETWUXA4SQohaTIqAEELUYnI5SAghajFpCQghRC0mRUAIIWoxKQJCCFGLSREQQohaTIqAEELUYv8fdD2ezr4L5JgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA1</th>\n",
       "      <th>PCA2</th>\n",
       "      <th>PCA3</th>\n",
       "      <th>PCA4</th>\n",
       "      <th>PCA5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-348.592018</td>\n",
       "      <td>-229.931577</td>\n",
       "      <td>-55.080246</td>\n",
       "      <td>-149.531934</td>\n",
       "      <td>42.462864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-356.012649</td>\n",
       "      <td>-48.518269</td>\n",
       "      <td>-57.298694</td>\n",
       "      <td>104.604300</td>\n",
       "      <td>24.270324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-378.717020</td>\n",
       "      <td>464.000945</td>\n",
       "      <td>-51.701006</td>\n",
       "      <td>-77.720386</td>\n",
       "      <td>50.065873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-360.866781</td>\n",
       "      <td>53.186261</td>\n",
       "      <td>-54.876773</td>\n",
       "      <td>-139.096309</td>\n",
       "      <td>15.110323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-348.210691</td>\n",
       "      <td>-237.227070</td>\n",
       "      <td>-55.586898</td>\n",
       "      <td>-122.053401</td>\n",
       "      <td>36.497974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3440</th>\n",
       "      <td>-109.434490</td>\n",
       "      <td>122.029500</td>\n",
       "      <td>4.020873</td>\n",
       "      <td>28.039266</td>\n",
       "      <td>47.827561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>224.738469</td>\n",
       "      <td>385.497880</td>\n",
       "      <td>89.280762</td>\n",
       "      <td>-53.736661</td>\n",
       "      <td>3.011049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3442</th>\n",
       "      <td>308.683484</td>\n",
       "      <td>467.560701</td>\n",
       "      <td>-20.246916</td>\n",
       "      <td>-97.509887</td>\n",
       "      <td>125.263644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3443</th>\n",
       "      <td>243.206119</td>\n",
       "      <td>-34.113563</td>\n",
       "      <td>85.760253</td>\n",
       "      <td>-6.815586</td>\n",
       "      <td>-20.120208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3444</th>\n",
       "      <td>315.947561</td>\n",
       "      <td>316.057191</td>\n",
       "      <td>-17.893989</td>\n",
       "      <td>2.458519</td>\n",
       "      <td>187.343058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3445 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PCA1        PCA2       PCA3        PCA4        PCA5\n",
       "0    -348.592018 -229.931577 -55.080246 -149.531934   42.462864\n",
       "1    -356.012649  -48.518269 -57.298694  104.604300   24.270324\n",
       "2    -378.717020  464.000945 -51.701006  -77.720386   50.065873\n",
       "3    -360.866781   53.186261 -54.876773 -139.096309   15.110323\n",
       "4    -348.210691 -237.227070 -55.586898 -122.053401   36.497974\n",
       "...          ...         ...        ...         ...         ...\n",
       "3440 -109.434490  122.029500   4.020873   28.039266   47.827561\n",
       "3441  224.738469  385.497880  89.280762  -53.736661    3.011049\n",
       "3442  308.683484  467.560701 -20.246916  -97.509887  125.263644\n",
       "3443  243.206119  -34.113563  85.760253   -6.815586  -20.120208\n",
       "3444  315.947561  316.057191 -17.893989    2.458519  187.343058\n",
       "\n",
       "[3445 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PCA \n",
    "dfpca1=dfsample4.copy()\n",
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=15)\n",
    "pca.fit(dfpca1)\n",
    "x_pca=pca.transform(dfpca1)\n",
    "x_pca.shape\n",
    "dfpca2 = pd.DataFrame(x_pca)\n",
    "per_var = np.round(pca.explained_variance_ratio_* 100, decimals=1)\n",
    "labels = ['PC' + str(x) for x in range(1, len(per_var)+1)]\n",
    " \n",
    "plt.plot(range(1,len(per_var)+1), per_var)\n",
    "plt.ylabel('Percentage of Explained Variance')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.title('Screen Plot')\n",
    "plt.show()\n",
    "\n",
    "dfpca3 = dfpca2.copy()\n",
    "dfpca3.columns =[\"PCA1\",\"PCA2\",\"PCA3\",\"PCA4\",\"PCA5\",\"PCA6\",\"PCA7\",\"PCA8\",\"PCA9\",\"PCA10\",\"PCA11\",\"PCA12\",\"PCA13\",\"PCA14\",\"PCA15\"]\n",
    "dfpca4 = dfpca3.copy()\n",
    "to_dropPca = [\"PCA6\",\"PCA7\",\"PCA8\",\"PCA9\",\"PCA10\",\"PCA11\",\"PCA12\",\"PCA13\",\"PCA14\",\"PCA15\"]\n",
    "dfpca4 = dfpca3.drop(columns= to_dropPca)\n",
    "dfpca4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from PCA and mean analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TWO DATA FRAMES :\n",
    "\n",
    "#PCA AND Correlation Dataframes:\n",
    "P_C_A = dfpca4.copy()\n",
    "Corr_dataframe = dataframe_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['team1_id', 'team2_id', 'game_id', 'team1_pt_overall_ncaa',\n",
       "       'team1_pt_career_school_wins', 'team1_pt_career_overall_wins',\n",
       "       'team1_pt_career_overall_losses', 'team1_pt_team_season_wins',\n",
       "       'team1_pt_team_season_losses', 'team1_pt_coach_season_wins',\n",
       "       'team1_pt_coach_season_losses', 'team2_pt_overall_ncaa',\n",
       "       'team2_pt_career_school_wins', 'team2_pt_career_overall_wins',\n",
       "       'team2_pt_career_overall_losses', 'team2_pt_team_season_wins',\n",
       "       'team2_pt_team_season_losses', 'team2_pt_coach_season_wins',\n",
       "       'team2_pt_coach_season_losses', 'team1_fg2pct', 'team1_fg3pct',\n",
       "       'team1_ftpct', 'team1_blockpct', 'team1_oppfg2pct',\n",
       "       'team1_oppfg3pct', 'team1_oppftpct', 'team1_oppblockpct',\n",
       "       'team1_f3grate', 'team1_oppf3grate', 'team1_arate',\n",
       "       'team1_opparate', 'team1_stlrate', 'team1_oppstlrate',\n",
       "       'team2_fg2pct', 'team2_fg3pct', 'team2_ftpct', 'team2_blockpct',\n",
       "       'team2_oppfg2pct', 'team2_oppfg3pct', 'team2_oppftpct',\n",
       "       'team2_oppblockpct', 'team2_f3grate', 'team2_oppf3grate',\n",
       "       'team2_arate', 'team2_opparate', 'team2_stlrate',\n",
       "       'team2_oppstlrate', 'team1_tempo', 'team1_adjtempo', 'team1_oe',\n",
       "       'team1_adjoe', 'team1_de', 'team1_adjde', 'team2_tempo',\n",
       "       'team2_adjtempo', 'team2_oe', 'team2_adjoe', 'team2_de',\n",
       "       'team2_adjde'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corr_dataframe.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team1_id</th>\n",
       "      <th>team2_id</th>\n",
       "      <th>game_id</th>\n",
       "      <th>team1_pt_overall_ncaa</th>\n",
       "      <th>team1_pt_career_school_wins</th>\n",
       "      <th>team1_pt_career_overall_wins</th>\n",
       "      <th>team1_pt_career_overall_losses</th>\n",
       "      <th>team1_pt_team_season_wins</th>\n",
       "      <th>team1_pt_team_season_losses</th>\n",
       "      <th>team1_pt_coach_season_wins</th>\n",
       "      <th>...</th>\n",
       "      <th>team1_oe</th>\n",
       "      <th>team1_adjoe</th>\n",
       "      <th>team1_de</th>\n",
       "      <th>team1_adjde</th>\n",
       "      <th>team2_tempo</th>\n",
       "      <th>team2_adjtempo</th>\n",
       "      <th>team2_oe</th>\n",
       "      <th>team2_adjoe</th>\n",
       "      <th>team2_de</th>\n",
       "      <th>team2_adjde</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1276</td>\n",
       "      <td>1104</td>\n",
       "      <td>2021-1276-1104</td>\n",
       "      <td>-0.904721</td>\n",
       "      <td>-0.764916</td>\n",
       "      <td>-1.190773</td>\n",
       "      <td>-1.453124</td>\n",
       "      <td>-0.069891</td>\n",
       "      <td>-0.723553</td>\n",
       "      <td>-0.130761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.728115</td>\n",
       "      <td>1.341227</td>\n",
       "      <td>0.010238</td>\n",
       "      <td>-1.239109</td>\n",
       "      <td>2.155986</td>\n",
       "      <td>2.070637</td>\n",
       "      <td>-0.408096</td>\n",
       "      <td>0.311308</td>\n",
       "      <td>-1.013335</td>\n",
       "      <td>-1.895828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1276</td>\n",
       "      <td>1400</td>\n",
       "      <td>2021-1276-1400</td>\n",
       "      <td>-0.904721</td>\n",
       "      <td>-0.764916</td>\n",
       "      <td>-1.190773</td>\n",
       "      <td>-1.453124</td>\n",
       "      <td>-0.069891</td>\n",
       "      <td>-0.723553</td>\n",
       "      <td>-0.130761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.728115</td>\n",
       "      <td>1.341227</td>\n",
       "      <td>0.010238</td>\n",
       "      <td>-1.239109</td>\n",
       "      <td>0.414576</td>\n",
       "      <td>0.528661</td>\n",
       "      <td>-0.243247</td>\n",
       "      <td>0.657151</td>\n",
       "      <td>0.177737</td>\n",
       "      <td>-0.586745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1276</td>\n",
       "      <td>1199</td>\n",
       "      <td>2021-1276-1199</td>\n",
       "      <td>-0.904721</td>\n",
       "      <td>-0.764916</td>\n",
       "      <td>-1.190773</td>\n",
       "      <td>-1.453124</td>\n",
       "      <td>-0.069891</td>\n",
       "      <td>-0.723553</td>\n",
       "      <td>-0.130761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.728115</td>\n",
       "      <td>1.341227</td>\n",
       "      <td>0.010238</td>\n",
       "      <td>-1.239109</td>\n",
       "      <td>0.650564</td>\n",
       "      <td>0.969869</td>\n",
       "      <td>0.632393</td>\n",
       "      <td>1.078928</td>\n",
       "      <td>0.440166</td>\n",
       "      <td>-0.364994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1276</td>\n",
       "      <td>1160</td>\n",
       "      <td>2021-1276-1160</td>\n",
       "      <td>-0.904721</td>\n",
       "      <td>-0.764916</td>\n",
       "      <td>-1.190773</td>\n",
       "      <td>-1.453124</td>\n",
       "      <td>-0.069891</td>\n",
       "      <td>-0.723553</td>\n",
       "      <td>-0.130761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.728115</td>\n",
       "      <td>1.341227</td>\n",
       "      <td>0.010238</td>\n",
       "      <td>-1.239109</td>\n",
       "      <td>-0.642955</td>\n",
       "      <td>-0.402446</td>\n",
       "      <td>0.386283</td>\n",
       "      <td>0.749669</td>\n",
       "      <td>-0.295817</td>\n",
       "      <td>-0.693021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276</td>\n",
       "      <td>1140</td>\n",
       "      <td>2021-1276-1140</td>\n",
       "      <td>-0.904721</td>\n",
       "      <td>-0.764916</td>\n",
       "      <td>-1.190773</td>\n",
       "      <td>-1.453124</td>\n",
       "      <td>-0.069891</td>\n",
       "      <td>-0.723553</td>\n",
       "      <td>-0.130761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.728115</td>\n",
       "      <td>1.341227</td>\n",
       "      <td>0.010238</td>\n",
       "      <td>-1.239109</td>\n",
       "      <td>0.658551</td>\n",
       "      <td>0.127286</td>\n",
       "      <td>0.155494</td>\n",
       "      <td>0.536667</td>\n",
       "      <td>-0.184187</td>\n",
       "      <td>-0.808156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3440</th>\n",
       "      <td>1260</td>\n",
       "      <td>1243</td>\n",
       "      <td>2018-1260.0-1243.0</td>\n",
       "      <td>-0.904721</td>\n",
       "      <td>-0.358653</td>\n",
       "      <td>-0.434171</td>\n",
       "      <td>0.397173</td>\n",
       "      <td>0.328250</td>\n",
       "      <td>-0.508855</td>\n",
       "      <td>1.523863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523436</td>\n",
       "      <td>-0.589248</td>\n",
       "      <td>-0.019193</td>\n",
       "      <td>0.087742</td>\n",
       "      <td>-0.531579</td>\n",
       "      <td>-0.684778</td>\n",
       "      <td>0.794721</td>\n",
       "      <td>-0.358267</td>\n",
       "      <td>0.071413</td>\n",
       "      <td>1.230190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>1276</td>\n",
       "      <td>1199</td>\n",
       "      <td>2018-1276.0-1199.0</td>\n",
       "      <td>0.454584</td>\n",
       "      <td>0.297620</td>\n",
       "      <td>0.864042</td>\n",
       "      <td>1.402975</td>\n",
       "      <td>0.328250</td>\n",
       "      <td>-0.079460</td>\n",
       "      <td>1.523863</td>\n",
       "      <td>...</td>\n",
       "      <td>1.420980</td>\n",
       "      <td>-0.167009</td>\n",
       "      <td>-0.832852</td>\n",
       "      <td>0.663690</td>\n",
       "      <td>1.355071</td>\n",
       "      <td>1.308537</td>\n",
       "      <td>1.492906</td>\n",
       "      <td>0.048226</td>\n",
       "      <td>0.690127</td>\n",
       "      <td>1.190108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3442</th>\n",
       "      <td>1437</td>\n",
       "      <td>1242</td>\n",
       "      <td>2018-1437.0-1242.0</td>\n",
       "      <td>0.825304</td>\n",
       "      <td>1.198692</td>\n",
       "      <td>0.872311</td>\n",
       "      <td>0.767232</td>\n",
       "      <td>0.427785</td>\n",
       "      <td>-0.723553</td>\n",
       "      <td>1.937519</td>\n",
       "      <td>...</td>\n",
       "      <td>3.664842</td>\n",
       "      <td>1.792178</td>\n",
       "      <td>-0.065688</td>\n",
       "      <td>1.416853</td>\n",
       "      <td>0.568967</td>\n",
       "      <td>0.262864</td>\n",
       "      <td>2.482001</td>\n",
       "      <td>0.893730</td>\n",
       "      <td>0.142803</td>\n",
       "      <td>1.190108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3443</th>\n",
       "      <td>1276</td>\n",
       "      <td>1260</td>\n",
       "      <td>2018-1276.0-1260.0</td>\n",
       "      <td>0.454584</td>\n",
       "      <td>0.297620</td>\n",
       "      <td>0.864042</td>\n",
       "      <td>1.402975</td>\n",
       "      <td>0.328250</td>\n",
       "      <td>-0.079460</td>\n",
       "      <td>1.523863</td>\n",
       "      <td>...</td>\n",
       "      <td>1.420980</td>\n",
       "      <td>-0.167009</td>\n",
       "      <td>-0.832852</td>\n",
       "      <td>0.663690</td>\n",
       "      <td>-0.751688</td>\n",
       "      <td>-0.750132</td>\n",
       "      <td>0.620175</td>\n",
       "      <td>-0.293228</td>\n",
       "      <td>-0.214147</td>\n",
       "      <td>-0.312948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3444</th>\n",
       "      <td>1437</td>\n",
       "      <td>1276</td>\n",
       "      <td>2018-1437.0-1276.0</td>\n",
       "      <td>0.825304</td>\n",
       "      <td>1.198692</td>\n",
       "      <td>0.872311</td>\n",
       "      <td>0.767232</td>\n",
       "      <td>0.427785</td>\n",
       "      <td>-0.723553</td>\n",
       "      <td>1.937519</td>\n",
       "      <td>...</td>\n",
       "      <td>3.664842</td>\n",
       "      <td>1.792178</td>\n",
       "      <td>-0.065688</td>\n",
       "      <td>1.416853</td>\n",
       "      <td>-0.908909</td>\n",
       "      <td>-1.044228</td>\n",
       "      <td>1.512300</td>\n",
       "      <td>0.113265</td>\n",
       "      <td>-1.047031</td>\n",
       "      <td>0.208111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3445 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      team1_id  team2_id             game_id  team1_pt_overall_ncaa  \\\n",
       "0         1276      1104      2021-1276-1104              -0.904721   \n",
       "1         1276      1400      2021-1276-1400              -0.904721   \n",
       "2         1276      1199      2021-1276-1199              -0.904721   \n",
       "3         1276      1160      2021-1276-1160              -0.904721   \n",
       "4         1276      1140      2021-1276-1140              -0.904721   \n",
       "...        ...       ...                 ...                    ...   \n",
       "3440      1260      1243  2018-1260.0-1243.0              -0.904721   \n",
       "3441      1276      1199  2018-1276.0-1199.0               0.454584   \n",
       "3442      1437      1242  2018-1437.0-1242.0               0.825304   \n",
       "3443      1276      1260  2018-1276.0-1260.0               0.454584   \n",
       "3444      1437      1276  2018-1437.0-1276.0               0.825304   \n",
       "\n",
       "      team1_pt_career_school_wins  team1_pt_career_overall_wins  \\\n",
       "0                       -0.764916                     -1.190773   \n",
       "1                       -0.764916                     -1.190773   \n",
       "2                       -0.764916                     -1.190773   \n",
       "3                       -0.764916                     -1.190773   \n",
       "4                       -0.764916                     -1.190773   \n",
       "...                           ...                           ...   \n",
       "3440                    -0.358653                     -0.434171   \n",
       "3441                     0.297620                      0.864042   \n",
       "3442                     1.198692                      0.872311   \n",
       "3443                     0.297620                      0.864042   \n",
       "3444                     1.198692                      0.872311   \n",
       "\n",
       "      team1_pt_career_overall_losses  team1_pt_team_season_wins  \\\n",
       "0                          -1.453124                  -0.069891   \n",
       "1                          -1.453124                  -0.069891   \n",
       "2                          -1.453124                  -0.069891   \n",
       "3                          -1.453124                  -0.069891   \n",
       "4                          -1.453124                  -0.069891   \n",
       "...                              ...                        ...   \n",
       "3440                        0.397173                   0.328250   \n",
       "3441                        1.402975                   0.328250   \n",
       "3442                        0.767232                   0.427785   \n",
       "3443                        1.402975                   0.328250   \n",
       "3444                        0.767232                   0.427785   \n",
       "\n",
       "      team1_pt_team_season_losses  team1_pt_coach_season_wins  ...  team1_oe  \\\n",
       "0                       -0.723553                   -0.130761  ...  0.728115   \n",
       "1                       -0.723553                   -0.130761  ...  0.728115   \n",
       "2                       -0.723553                   -0.130761  ...  0.728115   \n",
       "3                       -0.723553                   -0.130761  ...  0.728115   \n",
       "4                       -0.723553                   -0.130761  ...  0.728115   \n",
       "...                           ...                         ...  ...       ...   \n",
       "3440                    -0.508855                    1.523863  ...  0.523436   \n",
       "3441                    -0.079460                    1.523863  ...  1.420980   \n",
       "3442                    -0.723553                    1.937519  ...  3.664842   \n",
       "3443                    -0.079460                    1.523863  ...  1.420980   \n",
       "3444                    -0.723553                    1.937519  ...  3.664842   \n",
       "\n",
       "      team1_adjoe  team1_de  team1_adjde  team2_tempo  team2_adjtempo  \\\n",
       "0        1.341227  0.010238    -1.239109     2.155986        2.070637   \n",
       "1        1.341227  0.010238    -1.239109     0.414576        0.528661   \n",
       "2        1.341227  0.010238    -1.239109     0.650564        0.969869   \n",
       "3        1.341227  0.010238    -1.239109    -0.642955       -0.402446   \n",
       "4        1.341227  0.010238    -1.239109     0.658551        0.127286   \n",
       "...           ...       ...          ...          ...             ...   \n",
       "3440    -0.589248 -0.019193     0.087742    -0.531579       -0.684778   \n",
       "3441    -0.167009 -0.832852     0.663690     1.355071        1.308537   \n",
       "3442     1.792178 -0.065688     1.416853     0.568967        0.262864   \n",
       "3443    -0.167009 -0.832852     0.663690    -0.751688       -0.750132   \n",
       "3444     1.792178 -0.065688     1.416853    -0.908909       -1.044228   \n",
       "\n",
       "      team2_oe  team2_adjoe  team2_de  team2_adjde  \n",
       "0    -0.408096     0.311308 -1.013335    -1.895828  \n",
       "1    -0.243247     0.657151  0.177737    -0.586745  \n",
       "2     0.632393     1.078928  0.440166    -0.364994  \n",
       "3     0.386283     0.749669 -0.295817    -0.693021  \n",
       "4     0.155494     0.536667 -0.184187    -0.808156  \n",
       "...        ...          ...       ...          ...  \n",
       "3440  0.794721    -0.358267  0.071413     1.230190  \n",
       "3441  1.492906     0.048226  0.690127     1.190108  \n",
       "3442  2.482001     0.893730  0.142803     1.190108  \n",
       "3443  0.620175    -0.293228 -0.214147    -0.312948  \n",
       "3444  1.512300     0.113265 -1.047031     0.208111  \n",
       "\n",
       "[3445 rows x 59 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#standardizing variables\n",
    "\n",
    "nvars = ['team1_pt_overall_ncaa', 'team1_pt_career_school_wins',\n",
    "       'team1_pt_career_overall_wins', 'team1_pt_career_overall_losses',\n",
    "       'team1_pt_team_season_wins', 'team1_pt_team_season_losses',\n",
    "       'team1_pt_coach_season_wins', 'team1_pt_coach_season_losses',\n",
    "       'team2_pt_overall_ncaa', 'team2_pt_career_school_wins',\n",
    "       'team2_pt_career_overall_wins', 'team2_pt_career_overall_losses',\n",
    "       'team2_pt_team_season_wins', 'team2_pt_team_season_losses',\n",
    "       'team2_pt_coach_season_wins', 'team2_pt_coach_season_losses',\n",
    "       'team1_fg2pct', 'team1_fg3pct', 'team1_ftpct', 'team1_blockpct',\n",
    "       'team1_oppfg2pct', 'team1_oppfg3pct', 'team1_oppftpct',\n",
    "       'team1_oppblockpct', 'team1_f3grate', 'team1_oppf3grate', 'team1_arate',\n",
    "       'team1_opparate', 'team1_stlrate', 'team1_oppstlrate', 'team2_fg2pct',\n",
    "       'team2_fg3pct', 'team2_ftpct', 'team2_blockpct', 'team2_oppfg2pct',\n",
    "       'team2_oppfg3pct', 'team2_oppftpct', 'team2_oppblockpct',\n",
    "       'team2_f3grate', 'team2_oppf3grate', 'team2_arate', 'team2_opparate',\n",
    "       'team2_stlrate', 'team2_oppstlrate', 'team1_tempo', 'team1_adjtempo',\n",
    "       'team1_oe', 'team1_adjoe', 'team1_de', 'team1_adjde', 'team2_tempo',\n",
    "       'team2_adjtempo', 'team2_oe', 'team2_adjoe', 'team2_de', 'team2_adjde']\n",
    "\n",
    "Corr_dataframe[nvars] = (Corr_dataframe[nvars] - Corr_dataframe[nvars].mean())/Corr_dataframe[nvars].std()\n",
    "\n",
    "Corr_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-f898ede9d062>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[variable] = P_C_A[variable]\n"
     ]
    }
   ],
   "source": [
    "#creating final dataframe with finalized correlation variables + PCA variables\n",
    "\n",
    "final_df = Corr_dataframe[['team1_id','team2_id','team2_adjoe','team2_adjde','team2_oe','team2_pt_coach_season_losses','team2_pt_overall_ncaa','team1_pt_coach_season_wins','team1_adjoe','team1_pt_coach_season_losses','team2_pt_coach_season_wins','team1_adjde','team1_oe','team1_pt_overall_ncaa']]\n",
    "\n",
    "def PCA_retrieval(variable):\n",
    "    final_df[variable] = P_C_A[variable]\n",
    "    \n",
    "PCA_retrieval('PCA1')\n",
    "PCA_retrieval('PCA2')\n",
    "PCA_retrieval('PCA3')\n",
    "PCA_retrieval('PCA4')\n",
    "PCA_retrieval('PCA5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Efficiency and 3 Point Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-b49dea76755f>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"Net_eff\"] = ((df['team1_adjtempo']+df['team2_adjtempo'])/200)*((df['team1_adjoe']+df['team2_adjde'])/2-(df['team2_adjoe']+df['team1_adjde'])/2)\n",
      "<ipython-input-15-b49dea76755f>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"3_point_diff\"] = (df[\"team1_fg3pct\"]+df[\"team2_oppfg3pct\"])/2-(df[\"team2_fg3pct\"]+df['team1_oppfg3pct'])/2\n"
     ]
    }
   ],
   "source": [
    "#net efficiency\n",
    "final_df[\"Net_eff\"] = ((df['team1_adjtempo']+df['team2_adjtempo'])/200)*((df['team1_adjoe']+df['team2_adjde'])/2-(df['team2_adjoe']+df['team1_adjde'])/2)        \n",
    "\n",
    "#3 point diff\n",
    "final_df[\"3_point_diff\"] = (df[\"team1_fg3pct\"]+df[\"team2_oppfg3pct\"])/2-(df[\"team2_fg3pct\"]+df['team1_oppfg3pct'])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorizing Team's Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-a6665d8b6e31>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['team1_seed'] = None\n",
      "<ipython-input-16-a6665d8b6e31>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['team2_seed'] = None\n",
      "<ipython-input-16-a6665d8b6e31>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['team1_seed'][i] = '1-4'\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3418: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "<ipython-input-16-a6665d8b6e31>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['team1_seed'][i] = '5-8'\n",
      "<ipython-input-16-a6665d8b6e31>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['team1_seed'][i] = '9-12'\n",
      "<ipython-input-16-a6665d8b6e31>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['team1_seed'][i] = '13-16'\n",
      "<ipython-input-16-a6665d8b6e31>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['team2_seed'][i] = '1-4'\n",
      "<ipython-input-16-a6665d8b6e31>:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['team2_seed'][i] = '5-8'\n",
      "<ipython-input-16-a6665d8b6e31>:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['team2_seed'][i] = '9-12'\n",
      "<ipython-input-16-a6665d8b6e31>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['team2_seed'][i] = '13-16'\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3188: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "#simple categorization based on the team's current seed\n",
    "\n",
    "final_df['team1_seed'] = None\n",
    "final_df['team2_seed'] = None\n",
    "\n",
    "for i in df.index:\n",
    "    if df['team1_seed'][i] in [1,2,3,4]:\n",
    "        final_df['team1_seed'][i] = '1-4'\n",
    "    elif df['team1_seed'][i] in [5,6,7,8]:\n",
    "        final_df['team1_seed'][i] = '5-8'\n",
    "    elif df['team1_seed'][i] in [9,10,11,12]:\n",
    "        final_df['team1_seed'][i] = '9-12'\n",
    "    elif df['team1_seed'][i] in [13,14,15,16]:\n",
    "        final_df['team1_seed'][i] = '13-16'\n",
    "        \n",
    "for i in df.index:\n",
    "    if df['team2_seed'][i] in [1,2,3,4]:\n",
    "        final_df['team2_seed'][i] = '1-4'\n",
    "    elif df['team2_seed'][i] in [5,6,7,8]:\n",
    "        final_df['team2_seed'][i] = '5-8'\n",
    "    elif df['team2_seed'][i] in [9,10,11,12]:\n",
    "        final_df['team2_seed'][i] = '9-12'\n",
    "    elif df['team2_seed'][i] in [13,14,15,16]:\n",
    "        final_df['team2_seed'][i] = '13-16'\n",
    "        \n",
    "#creating dummies\n",
    "vars = ['team1_seed','team2_seed']\n",
    "final_df[vars] = final_df[vars].astype('category')\n",
    "final_df = pd.get_dummies(final_df,prefix_sep='_')\n",
    "rdummies = ['team1_seed_13-16','team2_seed_13-16']\n",
    "final_df = final_df.drop(columns=rdummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Collaboration Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-b9ea78f90dfc>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2018_19['team1_arate'][i] = 'collaboration'\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "<ipython-input-17-b9ea78f90dfc>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2018_19['team1_arate'][i] = 'individualization'\n",
      "<ipython-input-17-b9ea78f90dfc>:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2018_19['team2_arate'][i] = 'individualization'\n",
      "<ipython-input-17-b9ea78f90dfc>:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2018_19['team2_arate'][i] = 'collaboration'\n",
      "<ipython-input-17-b9ea78f90dfc>:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['team1_arate'][i] = 'collaboration'\n",
      "<ipython-input-17-b9ea78f90dfc>:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['team1_arate'][i] = 'individualization'\n",
      "<ipython-input-17-b9ea78f90dfc>:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['team1_arate'][i] = 'unranked'\n",
      "<ipython-input-17-b9ea78f90dfc>:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['team2_arate'][i] = 'individualization'\n",
      "<ipython-input-17-b9ea78f90dfc>:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['team2_arate'][i] = 'collaboration'\n",
      "<ipython-input-17-b9ea78f90dfc>:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['team2_arate'][i] = 'unranked'\n"
     ]
    }
   ],
   "source": [
    "#creating subset of dataset with only 2018/2019 values\n",
    "df_2018_19 = df[df['season'] > 2017]\n",
    "\n",
    "#resetting index of dataset so they follow a sequence (2019 and 2018 seasons are not sequent in original df)\n",
    "df_2018_19 = df_2018_19.reset_index(drop=True)\n",
    "\n",
    "#getting mean of collaborative variables for 2018/2019 seasons\n",
    "t1arate = df_2018_19['team1_arate'].mean()\n",
    "t2arate = df_2018_19['team2_arate'].mean()\n",
    "\n",
    "#adding categorical variable if above or below mean\n",
    "for i in df_2018_19.index:\n",
    "    if df_2018_19['team1_arate'][i] > t1arate:\n",
    "        df_2018_19['team1_arate'][i] = 'collaboration'\n",
    "    elif df_2018_19['team1_arate'][i] < t1arate:\n",
    "        df_2018_19['team1_arate'][i] = 'individualization'\n",
    "\n",
    "for i in df_2018_19.index:\n",
    "    if df_2018_19['team2_arate'][i] > t2arate:\n",
    "        df_2018_19['team2_arate'][i] = 'collaboration'\n",
    "    elif df_2018_19['team2_arate'][i] < t2arate:\n",
    "        df_2018_19['team2_arate'][i] = 'individualization'\n",
    "\n",
    "        \n",
    "#creating dict to register values\n",
    "colab = dict()\n",
    "\n",
    "#updating dict with each game that team 'collaborated'(+1) or 'individualized'(-1)\n",
    "for i in range(0,len(df_2018_19)):\n",
    "    if df_2018_19['team1_teamname'][i] in colab:\n",
    "        if df_2018_19['team1_arate'][i] == 'collaboration':\n",
    "            colab[df_2018_19['team1_teamname'][i]] += 1\n",
    "        if df_2018_19['team1_arate'][i] == 'individualization':\n",
    "            colab[df_2018_19['team1_teamname'][i]] += -1\n",
    "    elif df_2018_19['team1_teamname'][i] not in colab:\n",
    "        if df_2018_19['team1_arate'][i] == 'collaboration':\n",
    "            colab[df_2018_19['team1_teamname'][i]] = 1\n",
    "        if df_2018_19['team1_arate'][i] == 'individualization':\n",
    "            colab[df_2018_19['team1_teamname'][i]] = -1\n",
    "\n",
    "for i in range(0,len(df_2018_19)):\n",
    "    if df_2018_19['team2_teamname'][i] in colab:\n",
    "        if df_2018_19['team2_teamname'][i] == 'collaboration':\n",
    "            colab[df_2018_19['team2_teamname'][i]] += 1\n",
    "        if df_2018_19['team2_teamname'][i] == 'individualization':\n",
    "            colab[df_2018_19['team2_teamname'][i]] += -1\n",
    "    elif df_2018_19['team2_teamname'][i] not in colab:\n",
    "        if df_2018_19['team2_teamname'][i] == 'collaboration':\n",
    "            colab[df_2018_19['team2_teamname'][i]] = 1\n",
    "        if df_2018_19['team2_teamname'][i] == 'individualization':\n",
    "            colab[df_2018_19['team2_teamname'][i]] = -1\n",
    "\n",
    "#getting verdict if team overall is a collaboration or individualization team, and uploading it into df\n",
    "\n",
    "final_df['team1_arate'] = None\n",
    "final_df['team2_arate'] = None\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    if df['team1_teamname'][i] in colab:\n",
    "        if colab[df['team1_teamname'][i]] > 0:\n",
    "            final_df['team1_arate'][i] = 'collaboration'\n",
    "        elif colab[df['team1_teamname'][i]] <= 0:\n",
    "            final_df['team1_arate'][i] = 'individualization'\n",
    "    else:\n",
    "        final_df['team1_arate'][i] = 'unranked'\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    if df['team2_teamname'][i] in colab:\n",
    "        if colab[df['team2_teamname'][i]] > 0:\n",
    "            final_df['team2_arate'][i] = 'collaboration'\n",
    "        elif colab[df['team2_teamname'][i]] <= 0:\n",
    "            final_df['team2_arate'][i] = 'individualization'\n",
    "    else:\n",
    "        final_df['team2_arate'][i] = 'unranked'\n",
    "        \n",
    "#creating dummies\n",
    "vars = ['team1_arate','team2_arate']\n",
    "final_df[vars] = final_df[vars].astype('category')\n",
    "final_df = pd.get_dummies(final_df,prefix_sep='_')\n",
    "rdummies = ['team1_arate_unranked','team1_arate_unranked']\n",
    "final_df = final_df.drop(columns=rdummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coach Chance of Winning & Team Efficiency Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coach chances of winning \n",
    "\n",
    "df['Prob_coach1_win'] =1-((df['team1_pt_career_school_losses']/df['team1_pt_career_overall_losses']))\n",
    "df['Prob_coach2_win'] =1-((df['team2_pt_career_school_losses']/df['team2_pt_career_overall_losses']))\n",
    "\n",
    "final_df['Overall_prob_coach_win']=df['Prob_coach1_win']-df['Prob_coach2_win']\n",
    "\n",
    "\n",
    "#efficiency of team score\n",
    "\n",
    "df['Team1_scoring']=df['team1_fg2pct']+df['team1_fg3pct']+df['team1_ftpct']+df['team1_blockpct']\n",
    "df['Team1_opp_scoring']=df['team1_oppfg2pct']+df['team1_oppfg2pct']+df['team1_oppftpct']+df['team1_oppblockpct']\n",
    "df['Team1_eff'] = df['Team1_scoring']-df['Team1_opp_scoring']\n",
    "\n",
    "df['Team2_scoring']=df['team2_fg2pct']+df['team2_fg3pct']+df['team2_ftpct']+df['team2_blockpct']\n",
    "df['Team2_opp_scoring']=df['team2_oppfg2pct']+df['team2_oppfg2pct']+df['team2_oppftpct']+df['team2_oppblockpct']\n",
    "df['Team2_eff'] = df['Team2_scoring']-df['Team2_opp_scoring']\n",
    "\n",
    "final_df['Overall_eff']=df['Team1_eff']-df['Team2_eff']\n",
    "\n",
    "#standardizing variables\n",
    "\n",
    "himi_vars = ['Overall_prob_coach_win','Overall_eff']\n",
    "        \n",
    "final_df[himi_vars] = (final_df[himi_vars] - final_df[himi_vars].mean())/final_df[himi_vars].std()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Final Dataset for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['team1_id', 'team2_id', 'team2_adjoe', 'team2_adjde', 'team2_oe',\n",
       "       'team2_pt_coach_season_losses', 'team2_pt_overall_ncaa',\n",
       "       'team1_pt_coach_season_wins', 'team1_adjoe',\n",
       "       'team1_pt_coach_season_losses', 'team2_pt_coach_season_wins',\n",
       "       'team1_adjde', 'team1_oe', 'team1_pt_overall_ncaa', 'PCA1', 'PCA2',\n",
       "       'PCA3', 'PCA4', 'PCA5', 'Net_eff', '3_point_diff',\n",
       "       'team1_seed_1-4', 'team1_seed_5-8', 'team1_seed_9-12',\n",
       "       'team2_seed_1-4', 'team2_seed_5-8', 'team2_seed_9-12',\n",
       "       'team1_arate_collaboration', 'team1_arate_individualization',\n",
       "       'team2_arate_collaboration', 'team2_arate_individualization',\n",
       "       'team2_arate_unranked', 'Overall_prob_coach_win', 'Overall_eff',\n",
       "       'season'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FINAL DATASET\n",
    "\n",
    "nvars = ['team2_adjoe','team2_adjde','team2_oe','team2_pt_coach_season_losses','team2_pt_overall_ncaa','team1_pt_coach_season_wins','team1_adjoe','team1_pt_coach_season_losses','team2_pt_coach_season_wins','Net_eff','3_point_diff','Overall_prob_coach_win','Overall_eff']\n",
    "\n",
    "final_df[nvars] = final_df[nvars].astype('float64')\n",
    "\n",
    "final_df['season'] = df['season']\n",
    "\n",
    "final_df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excluding 2021 data from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting 2021 data\n",
    "\n",
    "#Create a 2021 dataframe to perform predictions on using machine learning models\n",
    "df_2021_prediction = final_df[final_df['season'] > 2020]\n",
    "\n",
    "#copy the 2021 prediction dataframe to use for non-machine learning predictions\n",
    "df_2021_post_prediction = df_2021_prediction.copy()\n",
    "\n",
    "#Drop the season variable on the machine learning dataframe\n",
    "df_2021_prediction = df_2021_prediction.drop(columns=['season','team1_id','team2_id'])\n",
    "\n",
    "#Append several rows to the 2021 post prediction df\n",
    "df_2021_post_prediction[['team1_id','team2_id', 'team1_lat', 'team1_long','team2_lat', 'team2_long','team1_teamname','team2_teamname']] = df[df['season'] > 2020][['team1_id','team2_id', 'team1_lat', 'team1_long','team2_lat', 'team2_long','team1_teamname','team2_teamname']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team1_id</th>\n",
       "      <th>team2_id</th>\n",
       "      <th>team2_adjoe</th>\n",
       "      <th>team2_adjde</th>\n",
       "      <th>team2_oe</th>\n",
       "      <th>team2_pt_coach_season_losses</th>\n",
       "      <th>team2_pt_overall_ncaa</th>\n",
       "      <th>team1_pt_coach_season_wins</th>\n",
       "      <th>team1_adjoe</th>\n",
       "      <th>team1_pt_coach_season_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>team2_seed_9-12</th>\n",
       "      <th>team1_arate_collaboration</th>\n",
       "      <th>team1_arate_individualization</th>\n",
       "      <th>team2_arate_collaboration</th>\n",
       "      <th>team2_arate_individualization</th>\n",
       "      <th>team2_arate_unranked</th>\n",
       "      <th>Overall_prob_coach_win</th>\n",
       "      <th>Overall_eff</th>\n",
       "      <th>season</th>\n",
       "      <th>dv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1341.0</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>-0.995272</td>\n",
       "      <td>3.776025</td>\n",
       "      <td>-0.048261</td>\n",
       "      <td>1.509062</td>\n",
       "      <td>-0.781148</td>\n",
       "      <td>0.076067</td>\n",
       "      <td>-1.438724</td>\n",
       "      <td>2.043386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.083909</td>\n",
       "      <td>-1.821252</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1125.0</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>-0.245912</td>\n",
       "      <td>0.821960</td>\n",
       "      <td>-0.542303</td>\n",
       "      <td>0.489905</td>\n",
       "      <td>1.511954</td>\n",
       "      <td>1.317035</td>\n",
       "      <td>0.466686</td>\n",
       "      <td>-0.777336</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.206286</td>\n",
       "      <td>1.180166</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1300.0</td>\n",
       "      <td>1295.0</td>\n",
       "      <td>-0.931261</td>\n",
       "      <td>3.626057</td>\n",
       "      <td>-0.081821</td>\n",
       "      <td>2.528219</td>\n",
       "      <td>-0.781148</td>\n",
       "      <td>-0.337589</td>\n",
       "      <td>-2.235432</td>\n",
       "      <td>2.748567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.083909</td>\n",
       "      <td>-0.070512</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1113.0</td>\n",
       "      <td>1385.0</td>\n",
       "      <td>-0.117298</td>\n",
       "      <td>1.118763</td>\n",
       "      <td>-0.410036</td>\n",
       "      <td>1.509062</td>\n",
       "      <td>-0.625270</td>\n",
       "      <td>0.489723</td>\n",
       "      <td>-0.388938</td>\n",
       "      <td>0.985615</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.495567</td>\n",
       "      <td>-0.553318</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>1278.0</td>\n",
       "      <td>-0.234061</td>\n",
       "      <td>0.626808</td>\n",
       "      <td>-1.037901</td>\n",
       "      <td>1.848781</td>\n",
       "      <td>-0.781148</td>\n",
       "      <td>0.076067</td>\n",
       "      <td>0.487725</td>\n",
       "      <td>2.043386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.753766</td>\n",
       "      <td>1.416304</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>1243.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>-0.589248</td>\n",
       "      <td>0.087742</td>\n",
       "      <td>0.523436</td>\n",
       "      <td>1.169343</td>\n",
       "      <td>-0.904721</td>\n",
       "      <td>1.523863</td>\n",
       "      <td>-0.358267</td>\n",
       "      <td>-0.777336</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493786</td>\n",
       "      <td>-0.628918</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>0.048226</td>\n",
       "      <td>1.190108</td>\n",
       "      <td>1.492906</td>\n",
       "      <td>1.169343</td>\n",
       "      <td>0.309766</td>\n",
       "      <td>1.523863</td>\n",
       "      <td>-0.167009</td>\n",
       "      <td>-0.072156</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024189</td>\n",
       "      <td>-1.046259</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>1242.0</td>\n",
       "      <td>1437.0</td>\n",
       "      <td>1.792178</td>\n",
       "      <td>1.416853</td>\n",
       "      <td>3.664842</td>\n",
       "      <td>-0.189533</td>\n",
       "      <td>0.825304</td>\n",
       "      <td>1.937519</td>\n",
       "      <td>0.893730</td>\n",
       "      <td>-1.129926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.496641</td>\n",
       "      <td>-0.195280</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>-0.293228</td>\n",
       "      <td>-0.312948</td>\n",
       "      <td>0.620175</td>\n",
       "      <td>-0.868971</td>\n",
       "      <td>-0.758846</td>\n",
       "      <td>1.523863</td>\n",
       "      <td>-0.167009</td>\n",
       "      <td>-0.072156</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079795</td>\n",
       "      <td>-1.315953</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>1437.0</td>\n",
       "      <td>1.792178</td>\n",
       "      <td>1.416853</td>\n",
       "      <td>3.664842</td>\n",
       "      <td>-0.189533</td>\n",
       "      <td>0.825304</td>\n",
       "      <td>1.937519</td>\n",
       "      <td>0.113265</td>\n",
       "      <td>-1.129926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.556990</td>\n",
       "      <td>-0.966757</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1167 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      team1_id  team2_id  team2_adjoe  team2_adjde  team2_oe  \\\n",
       "0       1341.0    1192.0    -0.995272     3.776025 -0.048261   \n",
       "1       1125.0    1396.0    -0.245912     0.821960 -0.542303   \n",
       "2       1300.0    1295.0    -0.931261     3.626057 -0.081821   \n",
       "3       1113.0    1385.0    -0.117298     1.118763 -0.410036   \n",
       "4       1257.0    1278.0    -0.234061     0.626808 -1.037901   \n",
       "...        ...       ...          ...          ...       ...   \n",
       "1162    1243.0    1260.0    -0.589248     0.087742  0.523436   \n",
       "1163    1276.0    1199.0     0.048226     1.190108  1.492906   \n",
       "1164    1242.0    1437.0     1.792178     1.416853  3.664842   \n",
       "1165    1276.0    1260.0    -0.293228    -0.312948  0.620175   \n",
       "1166    1276.0    1437.0     1.792178     1.416853  3.664842   \n",
       "\n",
       "      team2_pt_coach_season_losses  team2_pt_overall_ncaa  \\\n",
       "0                         1.509062              -0.781148   \n",
       "1                         0.489905               1.511954   \n",
       "2                         2.528219              -0.781148   \n",
       "3                         1.509062              -0.625270   \n",
       "4                         1.848781              -0.781148   \n",
       "...                            ...                    ...   \n",
       "1162                      1.169343              -0.904721   \n",
       "1163                      1.169343               0.309766   \n",
       "1164                     -0.189533               0.825304   \n",
       "1165                     -0.868971              -0.758846   \n",
       "1166                     -0.189533               0.825304   \n",
       "\n",
       "      team1_pt_coach_season_wins  team1_adjoe  team1_pt_coach_season_losses  \\\n",
       "0                       0.076067    -1.438724                      2.043386   \n",
       "1                       1.317035     0.466686                     -0.777336   \n",
       "2                      -0.337589    -2.235432                      2.748567   \n",
       "3                       0.489723    -0.388938                      0.985615   \n",
       "4                       0.076067     0.487725                      2.043386   \n",
       "...                          ...          ...                           ...   \n",
       "1162                    1.523863    -0.358267                     -0.777336   \n",
       "1163                    1.523863    -0.167009                     -0.072156   \n",
       "1164                    1.937519     0.893730                     -1.129926   \n",
       "1165                    1.523863    -0.167009                     -0.072156   \n",
       "1166                    1.937519     0.113265                     -1.129926   \n",
       "\n",
       "      ...  team2_seed_9-12  team1_arate_collaboration  \\\n",
       "0     ...              0.0                        0.0   \n",
       "1     ...              1.0                        1.0   \n",
       "2     ...              0.0                        0.0   \n",
       "3     ...              1.0                        0.0   \n",
       "4     ...              0.0                        1.0   \n",
       "...   ...              ...                        ...   \n",
       "1162  ...              1.0                        1.0   \n",
       "1163  ...              1.0                        1.0   \n",
       "1164  ...              0.0                        1.0   \n",
       "1165  ...              1.0                        1.0   \n",
       "1166  ...              0.0                        1.0   \n",
       "\n",
       "      team1_arate_individualization  team2_arate_collaboration  \\\n",
       "0                               1.0                        0.0   \n",
       "1                               0.0                        0.0   \n",
       "2                               1.0                        0.0   \n",
       "3                               1.0                        0.0   \n",
       "4                               0.0                        0.0   \n",
       "...                             ...                        ...   \n",
       "1162                            0.0                        1.0   \n",
       "1163                            0.0                        0.0   \n",
       "1164                            0.0                        0.0   \n",
       "1165                            0.0                        1.0   \n",
       "1166                            0.0                        1.0   \n",
       "\n",
       "      team2_arate_individualization  team2_arate_unranked  \\\n",
       "0                               0.0                   1.0   \n",
       "1                               0.0                   1.0   \n",
       "2                               0.0                   1.0   \n",
       "3                               0.0                   1.0   \n",
       "4                               0.0                   1.0   \n",
       "...                             ...                   ...   \n",
       "1162                            0.0                   0.0   \n",
       "1163                            1.0                   0.0   \n",
       "1164                            1.0                   0.0   \n",
       "1165                            0.0                   0.0   \n",
       "1166                            0.0                   0.0   \n",
       "\n",
       "      Overall_prob_coach_win  Overall_eff  season  dv  \n",
       "0                   0.083909    -1.821252  2019.0   0  \n",
       "1                  -1.206286     1.180166  2019.0   1  \n",
       "2                   0.083909    -0.070512  2019.0   0  \n",
       "3                   0.495567    -0.553318  2019.0   1  \n",
       "4                   1.753766     1.416304  2019.0   0  \n",
       "...                      ...          ...     ...  ..  \n",
       "1162                0.493786    -0.628918  2018.0   0  \n",
       "1163                0.024189    -1.046259  2018.0   1  \n",
       "1164                0.496641    -0.195280  2018.0   0  \n",
       "1165                0.079795    -1.315953  2018.0   1  \n",
       "1166                0.556990    -0.966757  2018.0   0  \n",
       "\n",
       "[1167 rows x 36 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter out all rows before 2020\n",
    "final_df = final_df[final_df['season'] < 2020]\n",
    "\n",
    "#creating DV\n",
    "final_df['dv'] = 1\n",
    "\n",
    "#creating DV = 0 and switching variables for DV = 0\n",
    "\n",
    "for i in range(0,len(final_df),2):\n",
    "    final_df.at[i,'dv'] = 0\n",
    "    \n",
    "        \n",
    "final_df = final_df.reset_index(drop=True)\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switching DV to include two-sided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-d71146746957>:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['PCA1'][i]=final_df['PCA1'][i]*(-1)\n",
      "<ipython-input-23-d71146746957>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['PCA2'][i]=final_df['PCA2'][i]*(-1)\n",
      "<ipython-input-23-d71146746957>:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['PCA3'][i]=final_df['PCA3'][i]*(-1)\n",
      "<ipython-input-23-d71146746957>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['PCA4'][i]=final_df['PCA4'][i]*(-1)\n",
      "<ipython-input-23-d71146746957>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['PCA5'][i]=final_df['PCA5'][i]*(-1)\n",
      "<ipython-input-23-d71146746957>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['Net_eff'][i]=final_df['Net_eff'][i]*(-1)\n",
      "<ipython-input-23-d71146746957>:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"3_point_diff\"][i]=final_df[\"3_point_diff\"][i]*(-1)\n",
      "<ipython-input-23-d71146746957>:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"Overall_prob_coach_win\"][i]=final_df[\"Overall_prob_coach_win\"][i]*(-1)\n",
      "<ipython-input-23-d71146746957>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"Overall_eff\"][i]=final_df[\"Overall_eff\"][i]*(-1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team1_id</th>\n",
       "      <th>team2_id</th>\n",
       "      <th>team2_adjoe</th>\n",
       "      <th>team2_adjde</th>\n",
       "      <th>team2_oe</th>\n",
       "      <th>team2_pt_coach_season_losses</th>\n",
       "      <th>team2_pt_overall_ncaa</th>\n",
       "      <th>team1_pt_coach_season_wins</th>\n",
       "      <th>team1_adjoe</th>\n",
       "      <th>team1_pt_coach_season_losses</th>\n",
       "      <th>...</th>\n",
       "      <th>team2_seed_9-12</th>\n",
       "      <th>team1_arate_collaboration</th>\n",
       "      <th>team1_arate_individualization</th>\n",
       "      <th>team2_arate_collaboration</th>\n",
       "      <th>team2_arate_individualization</th>\n",
       "      <th>team2_arate_unranked</th>\n",
       "      <th>Overall_prob_coach_win</th>\n",
       "      <th>Overall_eff</th>\n",
       "      <th>season</th>\n",
       "      <th>dv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1341.0</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>-0.995272</td>\n",
       "      <td>3.776025</td>\n",
       "      <td>-0.048261</td>\n",
       "      <td>1.509062</td>\n",
       "      <td>-0.781148</td>\n",
       "      <td>0.076067</td>\n",
       "      <td>-1.438724</td>\n",
       "      <td>2.043386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.083909</td>\n",
       "      <td>-1.821252</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1125.0</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>-0.245912</td>\n",
       "      <td>0.821960</td>\n",
       "      <td>-0.542303</td>\n",
       "      <td>0.489905</td>\n",
       "      <td>1.511954</td>\n",
       "      <td>1.317035</td>\n",
       "      <td>0.466686</td>\n",
       "      <td>-0.777336</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.206286</td>\n",
       "      <td>1.180166</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1300.0</td>\n",
       "      <td>1295.0</td>\n",
       "      <td>-0.931261</td>\n",
       "      <td>3.626057</td>\n",
       "      <td>-0.081821</td>\n",
       "      <td>2.528219</td>\n",
       "      <td>-0.781148</td>\n",
       "      <td>-0.337589</td>\n",
       "      <td>-2.235432</td>\n",
       "      <td>2.748567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.083909</td>\n",
       "      <td>-0.070512</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1113.0</td>\n",
       "      <td>1385.0</td>\n",
       "      <td>-0.117298</td>\n",
       "      <td>1.118763</td>\n",
       "      <td>-0.410036</td>\n",
       "      <td>1.509062</td>\n",
       "      <td>-0.625270</td>\n",
       "      <td>0.489723</td>\n",
       "      <td>-0.388938</td>\n",
       "      <td>0.985615</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.495567</td>\n",
       "      <td>-0.553318</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>1278.0</td>\n",
       "      <td>-0.234061</td>\n",
       "      <td>0.626808</td>\n",
       "      <td>-1.037901</td>\n",
       "      <td>1.848781</td>\n",
       "      <td>-0.781148</td>\n",
       "      <td>0.076067</td>\n",
       "      <td>0.487725</td>\n",
       "      <td>2.043386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.753766</td>\n",
       "      <td>1.416304</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>1243.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>-0.589248</td>\n",
       "      <td>0.087742</td>\n",
       "      <td>0.523436</td>\n",
       "      <td>1.169343</td>\n",
       "      <td>-0.904721</td>\n",
       "      <td>1.523863</td>\n",
       "      <td>-0.358267</td>\n",
       "      <td>-0.777336</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493786</td>\n",
       "      <td>-0.628918</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>0.048226</td>\n",
       "      <td>1.190108</td>\n",
       "      <td>1.492906</td>\n",
       "      <td>1.169343</td>\n",
       "      <td>0.309766</td>\n",
       "      <td>1.523863</td>\n",
       "      <td>-0.167009</td>\n",
       "      <td>-0.072156</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024189</td>\n",
       "      <td>-1.046259</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>1242.0</td>\n",
       "      <td>1437.0</td>\n",
       "      <td>1.792178</td>\n",
       "      <td>1.416853</td>\n",
       "      <td>3.664842</td>\n",
       "      <td>-0.189533</td>\n",
       "      <td>0.825304</td>\n",
       "      <td>1.937519</td>\n",
       "      <td>0.893730</td>\n",
       "      <td>-1.129926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.496641</td>\n",
       "      <td>-0.195280</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>-0.293228</td>\n",
       "      <td>-0.312948</td>\n",
       "      <td>0.620175</td>\n",
       "      <td>-0.868971</td>\n",
       "      <td>-0.758846</td>\n",
       "      <td>1.523863</td>\n",
       "      <td>-0.167009</td>\n",
       "      <td>-0.072156</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079795</td>\n",
       "      <td>-1.315953</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>1437.0</td>\n",
       "      <td>1.792178</td>\n",
       "      <td>1.416853</td>\n",
       "      <td>3.664842</td>\n",
       "      <td>-0.189533</td>\n",
       "      <td>0.825304</td>\n",
       "      <td>1.937519</td>\n",
       "      <td>0.113265</td>\n",
       "      <td>-1.129926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.556990</td>\n",
       "      <td>-0.966757</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1167 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      team1_id  team2_id  team2_adjoe  team2_adjde  team2_oe  \\\n",
       "0       1341.0    1192.0    -0.995272     3.776025 -0.048261   \n",
       "1       1125.0    1396.0    -0.245912     0.821960 -0.542303   \n",
       "2       1300.0    1295.0    -0.931261     3.626057 -0.081821   \n",
       "3       1113.0    1385.0    -0.117298     1.118763 -0.410036   \n",
       "4       1257.0    1278.0    -0.234061     0.626808 -1.037901   \n",
       "...        ...       ...          ...          ...       ...   \n",
       "1162    1243.0    1260.0    -0.589248     0.087742  0.523436   \n",
       "1163    1276.0    1199.0     0.048226     1.190108  1.492906   \n",
       "1164    1242.0    1437.0     1.792178     1.416853  3.664842   \n",
       "1165    1276.0    1260.0    -0.293228    -0.312948  0.620175   \n",
       "1166    1276.0    1437.0     1.792178     1.416853  3.664842   \n",
       "\n",
       "      team2_pt_coach_season_losses  team2_pt_overall_ncaa  \\\n",
       "0                         1.509062              -0.781148   \n",
       "1                         0.489905               1.511954   \n",
       "2                         2.528219              -0.781148   \n",
       "3                         1.509062              -0.625270   \n",
       "4                         1.848781              -0.781148   \n",
       "...                            ...                    ...   \n",
       "1162                      1.169343              -0.904721   \n",
       "1163                      1.169343               0.309766   \n",
       "1164                     -0.189533               0.825304   \n",
       "1165                     -0.868971              -0.758846   \n",
       "1166                     -0.189533               0.825304   \n",
       "\n",
       "      team1_pt_coach_season_wins  team1_adjoe  team1_pt_coach_season_losses  \\\n",
       "0                       0.076067    -1.438724                      2.043386   \n",
       "1                       1.317035     0.466686                     -0.777336   \n",
       "2                      -0.337589    -2.235432                      2.748567   \n",
       "3                       0.489723    -0.388938                      0.985615   \n",
       "4                       0.076067     0.487725                      2.043386   \n",
       "...                          ...          ...                           ...   \n",
       "1162                    1.523863    -0.358267                     -0.777336   \n",
       "1163                    1.523863    -0.167009                     -0.072156   \n",
       "1164                    1.937519     0.893730                     -1.129926   \n",
       "1165                    1.523863    -0.167009                     -0.072156   \n",
       "1166                    1.937519     0.113265                     -1.129926   \n",
       "\n",
       "      ...  team2_seed_9-12  team1_arate_collaboration  \\\n",
       "0     ...              0.0                        0.0   \n",
       "1     ...              1.0                        1.0   \n",
       "2     ...              0.0                        0.0   \n",
       "3     ...              1.0                        0.0   \n",
       "4     ...              0.0                        1.0   \n",
       "...   ...              ...                        ...   \n",
       "1162  ...              1.0                        1.0   \n",
       "1163  ...              1.0                        1.0   \n",
       "1164  ...              0.0                        1.0   \n",
       "1165  ...              1.0                        1.0   \n",
       "1166  ...              0.0                        1.0   \n",
       "\n",
       "      team1_arate_individualization  team2_arate_collaboration  \\\n",
       "0                               1.0                        0.0   \n",
       "1                               0.0                        0.0   \n",
       "2                               1.0                        0.0   \n",
       "3                               1.0                        0.0   \n",
       "4                               0.0                        0.0   \n",
       "...                             ...                        ...   \n",
       "1162                            0.0                        1.0   \n",
       "1163                            0.0                        0.0   \n",
       "1164                            0.0                        0.0   \n",
       "1165                            0.0                        1.0   \n",
       "1166                            0.0                        1.0   \n",
       "\n",
       "      team2_arate_individualization  team2_arate_unranked  \\\n",
       "0                               0.0                   1.0   \n",
       "1                               0.0                   1.0   \n",
       "2                               0.0                   1.0   \n",
       "3                               0.0                   1.0   \n",
       "4                               0.0                   1.0   \n",
       "...                             ...                   ...   \n",
       "1162                            0.0                   0.0   \n",
       "1163                            1.0                   0.0   \n",
       "1164                            1.0                   0.0   \n",
       "1165                            0.0                   0.0   \n",
       "1166                            0.0                   0.0   \n",
       "\n",
       "      Overall_prob_coach_win  Overall_eff  season  dv  \n",
       "0                   0.083909    -1.821252  2019.0   0  \n",
       "1                  -1.206286     1.180166  2019.0   1  \n",
       "2                   0.083909    -0.070512  2019.0   0  \n",
       "3                   0.495567    -0.553318  2019.0   1  \n",
       "4                   1.753766     1.416304  2019.0   0  \n",
       "...                      ...          ...     ...  ..  \n",
       "1162                0.493786    -0.628918  2018.0   0  \n",
       "1163                0.024189    -1.046259  2018.0   1  \n",
       "1164                0.496641    -0.195280  2018.0   0  \n",
       "1165                0.079795    -1.315953  2018.0   1  \n",
       "1166                0.556990    -0.966757  2018.0   0  \n",
       "\n",
       "[1167 rows x 36 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#switching variables for dv = 0\n",
    "        \n",
    "def switch_variables(team1_variable,team2_variable):\n",
    "    final_df[[str(team1_variable),str(team2_variable)]] = final_df[[str(team2_variable),str(team1_variable)]].where(final_df['dv'] == 0, final_df[[str(team1_variable),str(team2_variable)]].values)\n",
    "\n",
    "    \n",
    "switch_variables('team1_adjoe','team2_adjoe')\n",
    "switch_variables('team1_adjde','team2_adjde')\n",
    "switch_variables('team1_oe','team2_oe')\n",
    "switch_variables('team1_pt_coach_season_losses','team2_pt_coach_season_losses') \n",
    "switch_variables('team1_pt_overall_ncaa','team2_pt_overall_ncaa') \n",
    "switch_variables('team1_pt_coach_season_wins','team2_pt_coach_season_wins')\n",
    "switch_variables('team1_pt_coach_season_losses','team2_pt_coach_season_losses') \n",
    "switch_variables('team1_pt_coach_season_wins','team2_pt_coach_season_wins')\n",
    "switch_variables('team1_id', 'team2_id')\n",
    "\n",
    "#switching PCA value for DV=0\n",
    "for i in final_df.index:\n",
    "    if i in range(0,len(final_df),2):\n",
    "        final_df['PCA1'][i]=final_df['PCA1'][i]*(-1)\n",
    "        final_df['PCA2'][i]=final_df['PCA2'][i]*(-1)\n",
    "        final_df['PCA3'][i]=final_df['PCA3'][i]*(-1)\n",
    "        final_df['PCA4'][i]=final_df['PCA4'][i]*(-1)\n",
    "        final_df['PCA5'][i]=final_df['PCA5'][i]*(-1)\n",
    "\n",
    "#net efficiency\n",
    "for i in final_df.index:\n",
    "    if i in range(0,len(final_df),2):\n",
    "        final_df['Net_eff'][i]=final_df['Net_eff'][i]*(-1)\n",
    "        \n",
    "#3 point diff\n",
    "for i in final_df.index:\n",
    "    if i in range(0,len(final_df),2):\n",
    "        final_df[\"3_point_diff\"][i]=final_df[\"3_point_diff\"][i]*(-1)\n",
    "        \n",
    "#team seed\n",
    "switch_variables('team1_seed_1-4', 'team1_seed_1-4')\n",
    "switch_variables('team1_seed_5-8', 'team1_seed_5-8')\n",
    "switch_variables('team1_seed_9-12', 'team1_seed_9-12')\n",
    "\n",
    "#collaboration\n",
    "switch_variables('team1_arate_collaboration', 'team1_arate_collaboration')\n",
    "switch_variables('team1_arate_individualization', 'team1_arate_individualization')\n",
    "\n",
    "#coach chances of winning\n",
    "for i in final_df.index:\n",
    "    if i in range(0,len(final_df),2):\n",
    "        final_df[\"Overall_prob_coach_win\"][i]=final_df[\"Overall_prob_coach_win\"][i]*(-1)\n",
    "        \n",
    "#efficiency of team score        \n",
    "for i in final_df.index:\n",
    "    if i in range(0,len(final_df),2):\n",
    "        final_df[\"Overall_eff\"][i]=final_df[\"Overall_eff\"][i]*(-1)\n",
    "        \n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data partition\n",
    "\n",
    "#saving original dv for correlation to results\n",
    "df_original = final_df[final_df['season'] > 2018]\n",
    "df_original = df_original.drop(columns=['season'])\n",
    "\n",
    "#array of original 2019 dv\n",
    "labels_2019 = np.array(df_original['dv'])\n",
    "\n",
    "#test data\n",
    "df_test = final_df[final_df['season'] > 2018]\n",
    "#capturing the teamIds before removal\n",
    "df_test_teamIds = df_test[['team1_id', 'team2_id']]\n",
    "df_test = df_test.drop(columns=['season','team1_id', 'team2_id'])\n",
    "\n",
    "#historical data\n",
    "df_hist = final_df[final_df['season'] < 2019]\n",
    "#capturing the teamIds before removal\n",
    "df_hist_teamIds = df_hist[['team1_id', 'team2_id']]\n",
    "df_hist = df_hist.drop(columns=['season','team1_id', 'team2_id'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "part_size = 0.2\n",
    "\n",
    "\n",
    "nontest, test = train_test_split(df_hist, test_size = part_size, random_state = 1)\n",
    "\n",
    "dv = 'dv'\n",
    "\n",
    "#Training sets\n",
    "y = nontest[dv]\n",
    "x = nontest.drop(columns=[dv])\n",
    "\n",
    "#Test sets\n",
    "y_actual = test[dv]\n",
    "x_test = test.drop(columns=[dv])\n",
    "\n",
    "#2019 sets\n",
    "y_2019 = df_test[dv]\n",
    "x_2019 = df_test.drop(columns=[dv])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model Functions For Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(x_train, y_train, x_test, y_test, x_2019, y_2019):\n",
    "    \n",
    "    #Set placeholder variable for number of folds\n",
    "    kfolds = 5\n",
    "    \n",
    "    #Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 3)]\n",
    "\n",
    "    #Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "\n",
    "    #Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 3)]\n",
    "    max_depth.append(None)\n",
    "\n",
    "    #Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "\n",
    "    #Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "    #Create the random grid\n",
    "    param_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf}\n",
    "    \n",
    "    rf = RandomForestClassifier()\n",
    "    grid_cv = GridSearchCV(rf, param_grid, scoring = 'roc_auc', cv = kfolds, n_jobs=-1)\n",
    "    grid_cv.fit(x_train, y_train)\n",
    "    \n",
    "    #Set as global variable to use outside of function\n",
    "    global RFC_clf_optimal\n",
    "    RFC_clf_optimal = grid_cv.best_estimator_\n",
    "    \n",
    "    # Get the AUC of the best Random Forest Classifier - test\n",
    "    roc_auc_test = roc_auc_score(y_test, RFC_clf_optimal.predict_proba(x_test)[:,1])\n",
    "    \n",
    "    #getting the accuracy of the best Random Forest Classifier - test\n",
    "    Accuracy_score_test = RFC_clf_optimal.score(x_test, y_test)\n",
    "    \n",
    "    # Get the AUC of the best Random Forest Classifier - 2019\n",
    "    roc_auc_2019 = roc_auc_score(y_2019, RFC_clf_optimal.predict_proba(x_2019)[:,1])\n",
    "    \n",
    "    #getting the accuracy of the best Random Forest Classifier - 2019\n",
    "    Accuracy_score_2019 = RFC_clf_optimal.score(x_2019, y_2019)\n",
    "    \n",
    "    #Predictions on 2019 data\n",
    "    dv_2019 = RFC_clf_optimal.predict(x_2019)\n",
    "    predict_proba_2019 = RFC_clf_optimal.predict_proba(x_2019)\n",
    "    \n",
    "    #Log Loss\n",
    "    predictions_2019 = np.array(predict_proba_2019)\n",
    "    log_value = log_loss(labels_2019, predictions_2019)\n",
    "    \n",
    "    #return a dictionary to report the performance in a dataframe\n",
    "    return {\n",
    "        'Model': 'Random Forest Classifier',\n",
    "        'Accuracy_test': Accuracy_score_test,\n",
    "        'AUC_ROC Score_test': roc_auc_test,\n",
    "        'Accuracy_2019': Accuracy_score_2019,\n",
    "        'AUC_ROC Score_2019': roc_auc_2019,\n",
    "        'Log Loss': log_value\n",
    "    }#, #dv_2019, predict_proba_2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_regression(x_train, y_train, x_test, y_test, x_2019, y_2019):\n",
    "    kfolds = 5\n",
    "    min_alpha = 0.001\n",
    "    max_alpha = 100\n",
    "    n_candidates = 1000\n",
    "\n",
    "    alpha_list = list(np.linspace(min_alpha, max_alpha, num=n_candidates))\n",
    "    C_list = list(1/np.linspace(min_alpha, max_alpha, num=n_candidates))\n",
    "    \n",
    "    #Set as global variable to use outside of function\n",
    "    global LOG_clf_optimal\n",
    "    LOG_clf_optimal = LogisticRegressionCV(Cs=C_list, cv=kfolds, scoring='roc_auc', penalty='l1', solver='saga', max_iter=200, random_state = 1, n_jobs=-1).fit(x,y)\n",
    "    \n",
    "    # Get the AUC of the best LogisticRegression Classifier - test\n",
    "    roc_auc_test = roc_auc_score(y_test, LOG_clf_optimal.predict_proba(x_test)[:,1])\n",
    "    \n",
    "    #getting the accuracy of the best LogisticRegression Classifier - test\n",
    "    Accuracy_score_test = LOG_clf_optimal.score(x_test, y_test)\n",
    "    \n",
    "    # Get the AUC of the best LogisticRegression Classifier - 2019\n",
    "    roc_auc_2019 = roc_auc_score(y_2019, LOG_clf_optimal.predict_proba(x_2019)[:,1])\n",
    "    \n",
    "    #getting the accuracy of the best LogisticRegression Classifier - 2019\n",
    "    Accuracy_score_2019 = LOG_clf_optimal.score(x_2019, y_2019)\n",
    "    \n",
    "    #Predictions on 2019 data\n",
    "    dv_2019 = LOG_clf_optimal.predict(x_2019)\n",
    "    predict_proba_2019 = LOG_clf_optimal.predict_proba(x_2019)\n",
    "    \n",
    "    #Log Loss\n",
    "    predictions_2019 = np.array(predict_proba_2019)\n",
    "    log_value = log_loss(labels_2019, predictions_2019)\n",
    "    \n",
    "    #return a dictionary to report the performance in a dataframe\n",
    "    return {\n",
    "        'Model': 'Logistic Regression Classifier',\n",
    "        'Accuracy_test': Accuracy_score_test,\n",
    "        'AUC_ROC Score_test': roc_auc_test,\n",
    "        'Accuracy_2019': Accuracy_score_2019,\n",
    "        'AUC_ROC Score_2019': roc_auc_2019,\n",
    "        'Log Loss': log_value\n",
    "    }#, #dv_2019, predict_proba_2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(x_train, y_train, x_test, y_test, x_2019, y_2019):\n",
    "    #Set placeholder variable for number of folds\n",
    "    kfolds = 5\n",
    "    \n",
    "    #Create a parameter grid for number of neighbors\n",
    "    max_k = 200\n",
    "    \n",
    "    #Create a param grid\n",
    "    param_grid = {'n_neighbors': list(range(1, max_k+1))}\n",
    "    \n",
    "    #Utilize gridsearch to find optimal model\n",
    "    gridsearch = GridSearchCV(KNeighborsClassifier(metric='euclidean'), param_grid, scoring='roc_auc', cv=kfolds, n_jobs=-1)\n",
    "    gridsearch.fit(x_train,y_train)\n",
    "    \n",
    "    #Set as global variable to use outside of function\n",
    "    global clf_bestkNN\n",
    "    clf_bestkNN = gridsearch.best_estimator_\n",
    "    \n",
    "    # Get the AUC of the best KNN Classifier - test\n",
    "    roc_auc_test = roc_auc_score(y_test, clf_bestkNN.predict_proba(x_test)[:,1])\n",
    "    \n",
    "    #getting the accuracy of the best KNN Classifier - test\n",
    "    Accuracy_score_test = clf_bestkNN.score(x_test, y_test)\n",
    "    \n",
    "    # Get the AUC of the best KNN Classifier - 2019\n",
    "    roc_auc_2019 = roc_auc_score(y_2019, clf_bestkNN.predict_proba(x_2019)[:,1])\n",
    "    \n",
    "    #getting the accuracy of the best KNN Classifier - 2019\n",
    "    Accuracy_score_2019 = clf_bestkNN.score(x_2019, y_2019)\n",
    "    \n",
    "    #Predictions on 2019 data\n",
    "    dv_2019 = clf_bestkNN.predict(x_2019)\n",
    "    predict_proba_2019 = clf_bestkNN.predict_proba(x_2019)\n",
    "    \n",
    "    #Log Loss\n",
    "    predictions_2019 = np.array(predict_proba_2019)\n",
    "    log_value = log_loss(labels_2019, predictions_2019)\n",
    "    \n",
    "    #return a dictionary to report the performance in a dataframe\n",
    "    return {\n",
    "        'Model': 'K-Nearest Neighbor Classifier',\n",
    "        'Accuracy_test': Accuracy_score_test,\n",
    "        'AUC_ROC Score_test': roc_auc_test,\n",
    "        'Accuracy_2019': Accuracy_score_2019,\n",
    "        'AUC_ROC Score_2019': roc_auc_2019,\n",
    "        'Log Loss': log_value\n",
    "    }#, #dv_2019, predict_proba_2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(x_train, y_train, x_test, y_test, x_2019, y_2019):\n",
    "    #Placeholder kfolds\n",
    "    kfolds = 5\n",
    "\n",
    "    #The range of nodes\n",
    "    min_hls = 1\n",
    "    max_hls = 10\n",
    "\n",
    "    #Range of alpha\n",
    "    min_alpha = 0.0001\n",
    "    max_alpha = 10\n",
    "    n_alpha = 10\n",
    "    \n",
    "    #Set a parameter grid for the GridSearchCV\n",
    "    param_grid = {'hidden_layer_sizes':np.arange(min_hls, max_hls), 'alpha': list(np.linspace(min_alpha, max_alpha, num=n_alpha))}\n",
    "    \n",
    "    #Use a GridSearchCV to find the optimal model candidate\n",
    "    gridsearch = GridSearchCV(MLPClassifier(solver='lbfgs', max_iter=2000, random_state=1), param_grid, scoring='roc_auc', cv=kfolds, n_jobs=-1)\n",
    "    gridsearch.fit(x_train, y_train)\n",
    "    \n",
    "    #Set as global variable to use outside of function\n",
    "    global NN_clf_optimal\n",
    "    NN_clf_optimal = gridsearch.best_estimator_\n",
    "    \n",
    "    # Get the AUC of the best Neural Network - test\n",
    "    roc_auc_test = roc_auc_score(y_test, NN_clf_optimal.predict_proba(x_test)[:,1])\n",
    "    \n",
    "    #getting the accuracy of the best Neural Network - test\n",
    "    Accuracy_score_test = NN_clf_optimal.score(x_test, y_test)\n",
    "    \n",
    "    # Get the AUC of the best Neural Network - 2019\n",
    "    roc_auc_2019 = roc_auc_score(y_2019, NN_clf_optimal.predict_proba(x_2019)[:,1])\n",
    "    \n",
    "    #getting the accuracy of the best Neural Network - 2019\n",
    "    Accuracy_score_2019 = NN_clf_optimal.score(x_2019, y_2019)\n",
    "    \n",
    "    #Predictions on 2019 data\n",
    "    dv_2019 = NN_clf_optimal.predict(x_2019)\n",
    "    predict_proba_2019 = NN_clf_optimal.predict_proba(x_2019)\n",
    "    \n",
    "    #Log Loss\n",
    "    predictions_2019 = np.array(predict_proba_2019)\n",
    "    log_value = log_loss(labels_2019, predictions_2019)\n",
    "    \n",
    "    #return a dictionary to report the performance in a dataframe\n",
    "    return {\n",
    "        'Model': 'Neural Network',\n",
    "        'Accuracy_test': Accuracy_score_test,\n",
    "        'AUC_ROC Score_test': roc_auc_test,\n",
    "        'Accuracy_2019': Accuracy_score_2019,\n",
    "        'AUC_ROC Score_2019': roc_auc_2019,\n",
    "        'Log Loss': log_value\n",
    "    }#, #dv_2019, predict_proba_2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(x_train, y_train, x_test, y_test, x_2019, y_2019):\n",
    "    #Set placeholder variable for number of folds\n",
    "    kfolds = 5\n",
    "\n",
    "    # range of depths we will search for the best pruned tree\n",
    "    maximum_depth = 100\n",
    "    minimum_depth = 1\n",
    "    \n",
    "    #Set a parameter grid for the GridSearchCV\n",
    "    param_grid = {'max_depth': list(range(minimum_depth, maximum_depth+1))}\n",
    "    \n",
    "    gridsearch = GridSearchCV(DecisionTreeClassifier(criterion='entropy', random_state=1), param_grid, scoring='roc_auc', cv=kfolds, n_jobs=-1)\n",
    "    gridsearch.fit(x_train, y_train)\n",
    "    \n",
    "    #Set as global variable to use outside of function\n",
    "    global clf_BPT\n",
    "    clf_BPT = gridsearch.best_estimator_\n",
    "    \n",
    "    # Get the AUC of the best Decision Tree - test\n",
    "    roc_auc_test = roc_auc_score(y_test, clf_BPT.predict_proba(x_test)[:,1])\n",
    "    \n",
    "    #getting the accuracy of the best Decision Tree - test\n",
    "    Accuracy_score_test = clf_BPT.score(x_test, y_test)\n",
    "    \n",
    "    # Get the AUC of the best Decision Tree - 2019\n",
    "    roc_auc_2019 = roc_auc_score(y_2019, clf_BPT.predict_proba(x_2019)[:,1])\n",
    "    \n",
    "    #getting the accuracy of the best Decision Tree - 2019\n",
    "    Accuracy_score_2019 = clf_BPT.score(x_2019, y_2019)\n",
    "    \n",
    "    #Predictions on 2019 data\n",
    "    dv_2019 = clf_BPT.predict(x_2019)\n",
    "    predict_proba_2019 = clf_BPT.predict_proba(x_2019)\n",
    "    \n",
    "    #Log Loss\n",
    "    predictions_2019 = np.array(predict_proba_2019)\n",
    "    log_value = log_loss(labels_2019, predictions_2019)\n",
    "    \n",
    "    #return a dictionary to report the performance in a dataframe\n",
    "    return {\n",
    "        'Model': 'Decision Tree Classifier',\n",
    "        'Accuracy_test': Accuracy_score_test,\n",
    "        'AUC_ROC Score_test': roc_auc_test,\n",
    "        'Accuracy_2019': Accuracy_score_2019,\n",
    "        'AUC_ROC Score_2019': roc_auc_2019,\n",
    "        'Log Loss': log_value\n",
    "    }#, #dv_2019, predict_proba_2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADABoost Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ada_boost(x_train, y_train, x_test, y_test, x_2019, y_2019):\n",
    "    #Set placeholder variable for number of folds\n",
    "    kfolds = 5\n",
    "    \n",
    "    #Set a parameter grid for the GridSearchCV\n",
    "    param_grid = {\n",
    "                    \"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "                    \"base_estimator__splitter\" :   [\"best\", \"random\"],\n",
    "                    \"n_estimators\": [10, 50, 100, 500]\n",
    "             }\n",
    "    \n",
    "    #Assigning models and functions\n",
    "    DTC = DecisionTreeClassifier(random_state = 1, max_features = \"auto\", max_depth = 10)\n",
    "    ABC = AdaBoostClassifier(base_estimator = DTC, random_state=1)\n",
    "    \n",
    "    #Use a GridSearchCV to find the optimal model candidate\n",
    "    grid_cv = GridSearchCV(ABC, param_grid, scoring = 'roc_auc', cv = kfolds, n_jobs=-1)\n",
    "    grid_cv.fit(x_train, y_train)\n",
    "    \n",
    "    #Set as global variable to use outside of function\n",
    "    global ABC_clf_optimal\n",
    "    ABC_clf_optimal = grid_cv.best_estimator_\n",
    "    \n",
    "    # Get the AUC of the best ADA Boost - test\n",
    "    roc_auc_test = roc_auc_score(y_test, ABC_clf_optimal.predict_proba(x_test)[:,1])\n",
    "    \n",
    "    #getting the accuracy of the best ADA Boost - test\n",
    "    Accuracy_score_test = ABC_clf_optimal.score(x_test, y_test)\n",
    "    \n",
    "    # Get the AUC of the best ADA Boost - 2019\n",
    "    roc_auc_2019 = roc_auc_score(y_2019, ABC_clf_optimal.predict_proba(x_2019)[:,1])\n",
    "    \n",
    "    #getting the accuracy of the best ADA Boost - 2019\n",
    "    Accuracy_score_2019 = ABC_clf_optimal.score(x_2019, y_2019)\n",
    "    \n",
    "    #Predictions on 2019 data\n",
    "    dv_2019 = ABC_clf_optimal.predict(x_2019)\n",
    "    predict_proba_2019 = ABC_clf_optimal.predict_proba(x_2019)\n",
    "    \n",
    "    #Log Loss\n",
    "    predictions_2019 = np.array(predict_proba_2019)\n",
    "    log_value = log_loss(labels_2019, predictions_2019)\n",
    "    \n",
    "    #return a dictionary to report the performance in a dataframe\n",
    "    return {\n",
    "        'Model': 'ADA Boost',\n",
    "        'Accuracy_test': Accuracy_score_test,\n",
    "        'AUC_ROC Score_test': roc_auc_test,\n",
    "        'Accuracy_2019': Accuracy_score_2019,\n",
    "        'AUC_ROC Score_2019': roc_auc_2019,\n",
    "        'Log Loss': log_value\n",
    "    }#, dv_2019, predict_proba_2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "model_list = ['Decision Tree', 'Random Forest', 'Neural Network', 'KNN', 'Logistic Regression', 'ADA Boost']\n",
    "\n",
    "\n",
    "#Creating the data frame to store the results of each model\n",
    "model_performance_df = pd.DataFrame()\n",
    "\n",
    "for model in model_list:\n",
    "    if model == 'Decision Tree':\n",
    "        performance_dict = decision_tree(x, y, x_test, y_actual, x_2019, y_2019)\n",
    "        model_information_df = pd.DataFrame.from_dict([performance_dict])\n",
    "        model_performance_df = model_performance_df.append(model_information_df)\n",
    "    elif model == 'Random Forest':\n",
    "        performance_dict = random_forest(x, y, x_test, y_actual, x_2019, y_2019)\n",
    "        model_information_df = pd.DataFrame.from_dict([performance_dict])\n",
    "        model_performance_df = model_performance_df.append(model_information_df)\n",
    "    elif model == 'Neural Network':\n",
    "        performance_dict = neural_network(x, y, x_test, y_actual, x_2019, y_2019)\n",
    "        model_information_df = pd.DataFrame.from_dict([performance_dict])\n",
    "        model_performance_df = model_performance_df.append(model_information_df)\n",
    "    elif model == 'KNN':\n",
    "        performance_dict = KNN(x, y, x_test, y_actual, x_2019, y_2019)\n",
    "        model_information_df = pd.DataFrame.from_dict([performance_dict])\n",
    "        model_performance_df = model_performance_df.append(model_information_df)\n",
    "    elif model == 'Logistic Regression':\n",
    "        performance_dict = log_regression(x, y, x_test, y_actual, x_2019, y_2019)\n",
    "        model_information_df = pd.DataFrame.from_dict([performance_dict])\n",
    "        model_performance_df = model_performance_df.append(model_information_df)\n",
    "    elif model == 'ADA Boost':\n",
    "        performance_dict = ada_boost(x, y, x_test, y_actual, x_2019, y_2019)\n",
    "        model_information_df = pd.DataFrame.from_dict([performance_dict])\n",
    "        model_performance_df = model_performance_df.append(model_information_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>AUC_ROC Score_test</th>\n",
       "      <th>Accuracy_2019</th>\n",
       "      <th>AUC_ROC Score_2019</th>\n",
       "      <th>Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.813636</td>\n",
       "      <td>0.907203</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.933601</td>\n",
       "      <td>0.279314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.968182</td>\n",
       "      <td>0.995524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.241686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K-Nearest Neighbor Classifier</td>\n",
       "      <td>0.786364</td>\n",
       "      <td>0.852827</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.832442</td>\n",
       "      <td>1.431674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "      <td>0.853946</td>\n",
       "      <td>0.853946</td>\n",
       "      <td>0.868984</td>\n",
       "      <td>0.868984</td>\n",
       "      <td>0.444439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADA Boost</td>\n",
       "      <td>0.972727</td>\n",
       "      <td>0.998922</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.997326</td>\n",
       "      <td>0.084755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model  Accuracy_test  AUC_ROC Score_test  \\\n",
       "0        Decision Tree Classifier       0.813636            0.907203   \n",
       "0        Random Forest Classifier       0.968182            0.995524   \n",
       "0                  Neural Network       1.000000            1.000000   \n",
       "0   K-Nearest Neighbor Classifier       0.786364            0.852827   \n",
       "0  Logistic Regression Classifier       0.853946            0.853946   \n",
       "0                       ADA Boost       0.972727            0.998922   \n",
       "\n",
       "   Accuracy_2019  AUC_ROC Score_2019  Log Loss  \n",
       "0       0.850746            0.933601  0.279314  \n",
       "0       1.000000            1.000000  0.241686  \n",
       "0       1.000000            1.000000  0.012683  \n",
       "0       0.805970            0.832442  1.431674  \n",
       "0       0.868984            0.868984  0.444439  \n",
       "0       0.940299            0.997326  0.084755  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the 2021 dataset\n",
    "\n",
    "#Get the 2021 predictions\n",
    "pred_2021_NN = pd.DataFrame(NN_clf_optimal.predict_proba(df_2021_prediction))\n",
    "pred_2021_Random = pd.DataFrame(RFC_clf_optimal.predict_proba(df_2021_prediction))\n",
    "pred_2021_KNN = pd.DataFrame(clf_bestkNN.predict_proba(df_2021_prediction))\n",
    "pred_2021_LOG = pd.DataFrame(LOG_clf_optimal.predict_proba(df_2021_prediction))\n",
    "pred_2021_DEC = pd.DataFrame(clf_BPT.predict_proba(df_2021_prediction))\n",
    "pred_2021_ADA = pd.DataFrame(ABC_clf_optimal.predict_proba(df_2021_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Joining predictions into a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({'NN':pred_2021_NN[1],\n",
    "                            'Random':pred_2021_Random[1],\n",
    "                            'KNN':pred_2021_KNN[1],\n",
    "                            'LOG':pred_2021_LOG[1],\n",
    "                            'DEC':pred_2021_DEC[1],\n",
    "                            'ADA':pred_2021_ADA[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### checking for overall deviation from the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN        0.470456\n",
       "Random    0.249239\n",
       "KNN       0.355136\n",
       "LOG       0.235332\n",
       "DEC       0.333254\n",
       "ADA       0.470306\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deviation = predictions - 0.5\n",
    "\n",
    "(deviation.abs()).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De-extremizing final predictions (selected model: Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9563636363636364 0.23727272727272727\n"
     ]
    }
   ],
   "source": [
    "#retrieving maximum and minimum probabilities as reference \n",
    "\n",
    "print(pred_2021_Random[1].max(),\n",
    "pred_2021_Random[1].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating list for current and altered predictions\n",
    "original_predictions = []\n",
    "altered_predictions = []\n",
    "\n",
    "#placing exponential formula to equally affect values above and below 50%\n",
    "#19.9986137537 is the value that makes a .9999 or .0001 prediction be affected by 10%\n",
    "for i in pred_2021_Random[1]:\n",
    "    if i > 0.5:\n",
    "        altered_predictions.append(i - ( 2**(i) /19.9986137537))\n",
    "        original_predictions.append(i)\n",
    "    elif i < 0.5:\n",
    "        altered_predictions.append(i + ( 2**(1-i) /19.9986137537))\n",
    "        original_predictions.append(i)\n",
    "    else:\n",
    "        altered_predictions.append(i)\n",
    "        original_predictions.append(i)\n",
    "\n",
    "#creating df to compare values\n",
    "df_comparison = pd.DataFrame({'original_predictions':original_predictions,'altered_predictions':altered_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max alteration: 0.09702736753842267\n",
      "Max value: 0.8593362688252137\n",
      "Min value: 0.32211335925468554\n"
     ]
    }
   ],
   "source": [
    "#checking for the actual effects of our alterations\n",
    "df_diff = df_comparison['altered_predictions'] - df_comparison['original_predictions']\n",
    "\n",
    "print('Max alteration: '+ str((df_diff.abs()).max()))\n",
    "print('Max value: ' + str(df_comparison['altered_predictions'].max()))\n",
    "print('Min value: ' + str(df_comparison['altered_predictions'].min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Exogenonus Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-72ad3dc5f395>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_copy['prob'] = df_comparison['altered_predictions']\n",
      "<ipython-input-48-72ad3dc5f395>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_copy['game_id'] = df[df['season']==2021]['game_id']\n"
     ]
    }
   ],
   "source": [
    "##Data set import and prep\n",
    "#For the sportsbetting we can only use the games that are known at this point which is the first round. \n",
    "#Therefore we have labeled the games that are happening in the first round\n",
    "prediction_df_2021 = pd.read_csv('df_2021_post_prediction.csv')\n",
    "\n",
    "#Remove unnecessary columns\n",
    "df_copy = prediction_df_2021[['team1_id','team2_id', 'team1_lat', 'team1_long','team2_lat', 'team2_long','team1_teamname','team2_teamname','First Round']]\n",
    "\n",
    "#Add the predicted probability and game id\n",
    "df_copy['prob'] = df_comparison['altered_predictions']\n",
    "df_copy['game_id'] = df[df['season']==2021]['game_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dad's Intuition Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-3468c6e7e1c8>:265: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_copy['team1_dad_intuition'] = None\n",
      "<ipython-input-49-3468c6e7e1c8>:270: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_copy['team1_dad_intuition'][i] = dad_intuition[df_copy['team1_teamname'][i]]\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3418: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "<ipython-input-49-3468c6e7e1c8>:274: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_copy['team2_dad_intuition'] = None\n",
      "<ipython-input-49-3468c6e7e1c8>:279: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_copy['team2_dad_intuition'][i] = dad_intuition[df_copy['team2_teamname'][i]]\n"
     ]
    }
   ],
   "source": [
    "#creating set with all team names\n",
    "team_names = set()\n",
    "\n",
    "#adding team names from teamname columns to set\n",
    "for i in df_copy['team1_teamname']:\n",
    "    team_names.add(i)\n",
    "for i in df_copy['team2_teamname']:\n",
    "    team_names.add(i)\n",
    "\n",
    "#creating dictionary with team names and ranking value (top, bottom, and unranked)\n",
    "dad_intuition = {'UAB': 'unranked',\n",
    " 'Ohio St': 'top',\n",
    " 'Texas': 'bottom',\n",
    " 'Portland St': 'unranked',\n",
    " 'W Kentucky': 'unranked',\n",
    " 'NC A&T': 'unranked',\n",
    " 'N Dakota St': 'unranked',\n",
    " 'Oregon': 'unranked',\n",
    " 'WI Green Bay': 'unranked',\n",
    " 'Alabama': 'unranked',\n",
    " 'Washington St': 'unranked',\n",
    " 'Texas A&M': 'unranked',\n",
    " 'Cornell': 'unranked',\n",
    " 'Ohio': 'unranked',\n",
    " 'Villanova': 'top',\n",
    " 'Vermont': 'unranked',\n",
    " 'St Louis': 'unranked',\n",
    " 'ETSU': 'unranked',\n",
    " 'Florida A&M': 'unranked',\n",
    " 'Winthrop': 'unranked',\n",
    " 'BYU': 'unranked',\n",
    " 'Rhode Island': 'unranked',\n",
    " 'San Diego': 'unranked',\n",
    " 'UC Irvine': 'unranked',\n",
    " \"St Mary's CA\": 'unranked',\n",
    " 'MS Valley St': 'unranked',\n",
    " 'Ark Pine Bluff': 'unranked',\n",
    " 'New Orleans': 'unranked',\n",
    " 'Jacksonville St': 'unranked',\n",
    " 'Troy': 'unranked',\n",
    " 'SF Austin': 'unranked',\n",
    " 'Creighton': 'bottom',\n",
    " 'Norfolk St': 'unranked',\n",
    " 'Santa Barbara': 'unranked',\n",
    " 'F Dickinson': 'unranked',\n",
    " 'Cincinnati': 'unranked',\n",
    " 'Memphis': 'unranked',\n",
    " 'Buffalo': 'unranked',\n",
    " 'Oklahoma': 'unranked',\n",
    " 'Miami FL': 'unranked',\n",
    " 'Yale': 'unranked',\n",
    " 'St Bonaventure': 'unranked',\n",
    " 'Wagner': 'unranked',\n",
    " 'Prairie View': 'unranked',\n",
    " 'CS Northridge': 'unranked',\n",
    " 'Georgetown': 'unranked',\n",
    " 'Gonzaga': 'top',\n",
    " 'Duke': 'unranked',\n",
    " 'G Washington': 'unranked',\n",
    " 'Tennessee': 'bottom',\n",
    " 'Syracuse': 'unranked',\n",
    " 'Valparaiso': 'unranked',\n",
    " 'Alcorn St': 'unranked',\n",
    " 'Colgate': 'unranked',\n",
    " 'Penn St': 'unranked',\n",
    " 'Stony Brook': 'unranked',\n",
    " 'Drake': 'unranked',\n",
    " 'Detroit': 'unranked',\n",
    " 'Wichita St': 'unranked',\n",
    " 'TX Southern': 'unranked',\n",
    " 'Dayton': 'unranked',\n",
    " 'LSU': 'unranked',\n",
    " 'Bradley': 'unranked',\n",
    " 'Mercer': 'unranked',\n",
    " 'Long Island': 'unranked',\n",
    " 'Virginia Tech': 'bottom',\n",
    " 'Auburn': 'unranked',\n",
    " 'Murray St': 'unranked',\n",
    " 'Illinois': 'top',\n",
    " 'UNC Greensboro': 'unranked',\n",
    " 'Wofford': 'unranked',\n",
    " 'UMBC': 'unranked',\n",
    " 'TCU': 'unranked',\n",
    " 'Sam Houston St': 'unranked',\n",
    " 'New Mexico St': 'unranked',\n",
    " 'Iowa': 'top',\n",
    " 'Wake Forest': 'unranked',\n",
    " 'Pittsburgh': 'unranked',\n",
    " 'James Madison': 'unranked',\n",
    " 'Florida St': 'top',\n",
    " 'Monmouth NJ': 'unranked',\n",
    " 'USC': 'bottom',\n",
    " 'Richmond': 'unranked',\n",
    " 'Oregon St': 'unranked',\n",
    " 'Arkansas': 'bottom',\n",
    " 'Utah': 'unranked',\n",
    " 'North Texas': 'unranked',\n",
    " 'Missouri': 'bottom',\n",
    " 'CS Fullerton': 'unranked',\n",
    " 'Mississippi St': 'unranked',\n",
    " 'ULL': 'unranked',\n",
    " 'UT Arlington': 'unranked',\n",
    " 'Massachusetts': 'unranked',\n",
    " 'Houston': 'top',\n",
    " 'Iowa St': 'unranked',\n",
    " 'Indiana St': 'unranked',\n",
    " 'Pacific': 'unranked',\n",
    " 'S Carolina St': 'unranked',\n",
    " 'Alabama A&M': 'top',\n",
    " 'Boston Univ': 'unranked',\n",
    " 'Nebraska': 'unranked',\n",
    " 'N Colorado': 'unranked',\n",
    " 'IL Chicago': 'unranked',\n",
    " 'Georgia': 'unranked',\n",
    " 'West Virginia': 'top',\n",
    " 'Clemson': 'unranked',\n",
    " 'Long Beach St': 'unranked',\n",
    " 'FL Gulf Coast': 'unranked',\n",
    " 'Kentucky': 'unranked',\n",
    " 'UNC Wilmington': 'unranked',\n",
    " 'Robert Morris': 'unranked',\n",
    " 'Pepperdine': 'unranked',\n",
    " 'UNLV': 'unranked',\n",
    " 'Washington': 'unranked',\n",
    " 'Northwestern LA': 'unranked',\n",
    " 'Princeton': 'unranked',\n",
    " 'Kansas': 'bottom',\n",
    " 'DePaul': 'unranked',\n",
    " 'Lehigh': 'unranked',\n",
    " 'Stanford': 'unranked',\n",
    " 'Albany NY': 'unranked',\n",
    " 'Delaware': 'unranked',\n",
    " 'IUPUI': 'unranked',\n",
    " 'New Mexico': 'unranked',\n",
    " 'FL Atlantic': 'unranked',\n",
    " 'Maryland': 'unranked',\n",
    " 'NC State': 'unranked',\n",
    " 'NC Central': 'unranked',\n",
    " 'Mississippi': 'unranked',\n",
    " 'UTEP': 'unranked',\n",
    " 'Morgan St': 'unranked',\n",
    " 'Colorado St': 'unranked',\n",
    " 'Colorado': 'unranked',\n",
    " 'Tulsa': 'unranked',\n",
    " 'Boston College': 'unranked',\n",
    " 'Gardner Webb': 'unranked',\n",
    " 'Utah St': 'unranked',\n",
    " 'Southern Miss': 'unranked',\n",
    " 'N Kentucky': 'unranked',\n",
    " 'Niagara': 'unranked',\n",
    " 'Abilene Chr': 'unranked',\n",
    " \"St Peter's\": 'unranked',\n",
    " 'Providence': 'unranked',\n",
    " 'Austin Peay': 'unranked',\n",
    " 'C Michigan': 'unranked',\n",
    " 'Northern Iowa': 'unranked',\n",
    " 'North Dakota': 'unranked',\n",
    " 'Chattanooga': 'unranked',\n",
    " 'Vanderbilt': 'unranked',\n",
    " 'Col Charleston': 'unranked',\n",
    " 'La Salle': 'unranked',\n",
    " 'Bucknell': 'unranked',\n",
    " 'McNeese St': 'unranked',\n",
    " 'Southern Univ': 'unranked',\n",
    " 'Seton Hall': 'unranked',\n",
    " 'Marshall': 'unranked',\n",
    " 'Virginia': 'bottom',\n",
    " 'SE Louisiana': 'unranked',\n",
    " 'WI Milwaukee': 'unranked',\n",
    " 'Liberty': 'unranked',\n",
    " 'Morehead St': 'unranked',\n",
    " 'Arizona St': 'unranked',\n",
    " 'Oklahoma St': 'top',\n",
    " 'North Carolina': 'unranked',\n",
    " 'Binghamton': 'unranked',\n",
    " 'MTSU': 'unranked',\n",
    " 'South Florida': 'unranked',\n",
    " 'Loyola-Chicago': 'unranked',\n",
    " 'UCLA': 'unranked',\n",
    " 'American Univ': 'unranked',\n",
    " 'UCF': 'unranked',\n",
    " 'Siena': 'unranked',\n",
    " 'Kent': 'unranked',\n",
    " 'Butler': 'unranked',\n",
    " \"Mt St Mary's\": 'unranked',\n",
    " 'Loyola MD': 'unranked',\n",
    " 'Old Dominion': 'unranked',\n",
    " 'Georgia St': 'unranked',\n",
    " 'Marquette': 'unranked',\n",
    " 'South Alabama': 'unranked',\n",
    " 'Akron': 'unranked',\n",
    " 'Radford': 'unranked',\n",
    " 'Michigan': 'unranked',\n",
    " 'Manhattan': 'unranked',\n",
    " 'Alabama St': 'unranked',\n",
    " 'Jackson St': 'unranked',\n",
    " 'S Dakota St': 'unranked',\n",
    " 'California': 'unranked',\n",
    " 'North Florida': 'unranked',\n",
    " 'Notre Dame': 'unranked',\n",
    " 'Arizona': 'unranked',\n",
    " 'Purdue': 'unranked',\n",
    " 'Harvard': 'unranked',\n",
    " 'Weber St': 'unranked',\n",
    " 'Lafayette': 'unranked',\n",
    " 'Miami OH': 'unranked',\n",
    " 'Penn': 'unranked',\n",
    " 'Nevada': 'unranked',\n",
    " 'San Diego St': 'bottom',\n",
    " 'Coastal Car': 'unranked',\n",
    " 'Lipscomb': 'unranked',\n",
    " 'Fresno St': 'unranked',\n",
    " 'SMU': 'unranked',\n",
    " 'Northwestern': 'unranked',\n",
    " 'Michigan St': 'unranked',\n",
    " \"St John's\": 'unranked',\n",
    " 'Florida': 'unranked',\n",
    " 'Hawaii': 'unranked',\n",
    " 'Georgia Tech': 'unranked',\n",
    " 'Charlotte': 'unranked',\n",
    " 'Oral Roberts': 'unranked',\n",
    " 'George Mason': 'unranked',\n",
    " 'Northeastern': 'unranked',\n",
    " \"St Joseph's PA\": 'unranked',\n",
    " 'Oakland': 'unranked',\n",
    " 'UT San Antonio': 'unranked',\n",
    " 'Wisconsin': 'bottom',\n",
    " 'UC Davis': 'unranked',\n",
    " 'E Washington': 'unranked',\n",
    " 'CS Bakersfield': 'unranked',\n",
    " 'VA Commonwealth': 'unranked',\n",
    " 'Belmont': 'unranked',\n",
    " 'Xavier': 'unranked',\n",
    " 'Central Conn': 'unranked',\n",
    " 'Air Force': 'unranked',\n",
    " 'E Kentucky': 'unranked',\n",
    " 'Minnesota': 'unranked',\n",
    " 'Baylor': 'top',\n",
    " 'Texas Tech': 'bottom',\n",
    " 'Wright St': 'unranked',\n",
    " 'Delaware St': 'unranked',\n",
    " 'S Illinois': 'unranked',\n",
    " 'Ark Little Rock': 'unranked',\n",
    " 'Iona': 'unranked',\n",
    " 'Connecticut': 'unranked',\n",
    " 'UNC Asheville': 'unranked',\n",
    " 'Davidson': 'unranked',\n",
    " 'Boise St': 'unranked',\n",
    " 'Indiana': 'unranked',\n",
    " 'Wyoming': 'unranked',\n",
    " 'Louisville': 'unranked',\n",
    " 'Cal Poly SLO': 'unranked',\n",
    " 'South Carolina': 'unranked',\n",
    " 'TAM C. Christi': 'unranked',\n",
    " 'Cleveland St': 'unranked',\n",
    " 'Lamar': 'unranked',\n",
    " 'Montana': 'unranked',\n",
    " 'W Michigan': 'top',\n",
    " 'Kansas St': 'unranked',\n",
    " 'Temple': 'unranked',\n",
    " 'Holy Cross': 'unranked',\n",
    " 'Hampton': 'unranked'}\n",
    "\n",
    "#creating column for team1 variable        \n",
    "df_copy['team1_dad_intuition'] = None\n",
    "\n",
    "#associating team1_name with intuition variable\n",
    "for i in range(0,len(df_copy)):\n",
    "    if df_copy['team1_teamname'][i] in dad_intuition:\n",
    "        df_copy['team1_dad_intuition'][i] = dad_intuition[df_copy['team1_teamname'][i]]\n",
    "\n",
    "\n",
    "#creating column for team2 variable  \n",
    "df_copy['team2_dad_intuition'] = None\n",
    "\n",
    "#associating team2_name with intuition variable        \n",
    "for i in range(0,len(df_copy)):\n",
    "    if df_copy['team2_teamname'][i] in dad_intuition:\n",
    "        df_copy['team2_dad_intuition'][i] = dad_intuition[df_copy['team2_teamname'][i]]\n",
    "\n",
    "        \n",
    "#Assign unranked to all teams that are not ranked\n",
    "df_copy = df_copy.fillna(value='unranked')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COVID Affected Homeground Variable\n",
    "Issue: the teams did not have covid restrictions prior to 2020, so we should not use it to train data<br><br>\n",
    "We should negatively impact the team's winning probability if they faced covid restrictions after rendering results<br><br>\n",
    "source: https://wallethub.com/edu/states-coronavirus-restrictions/73818"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-d8fdaa210ef5>:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_copy['team1_covid_restrictions'][i] = team_restrictions[df_copy['team1_teamname'][i]]\n",
      "<ipython-input-50-d8fdaa210ef5>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_copy['team2_covid_restrictions'][i] = team_restrictions[df_copy['team2_teamname'][i]]\n"
     ]
    }
   ],
   "source": [
    "#creating dictionary with each team name and latitude/longitude for future use\n",
    "team_location = dict()\n",
    "\n",
    "#applying data to dict\n",
    "for i in range(0,(len(df_copy))):\n",
    "    team_location[df_copy['team1_teamname'][i]] = str(df_copy['team1_lat'][i])+','+str(df_copy['team1_long'][i])\n",
    "for i in range(0,(len(df_copy))):\n",
    "    team_location[df_copy['team2_teamname'][i]] = str(df_copy['team2_lat'][i])+','+str(df_copy['team2_long'][i])\n",
    "\n",
    "#library to retrieve location based on coordinates    \n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# initialize Nominatim API  \n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "\n",
    "#retrieving state based on location\n",
    "for i in team_location:\n",
    "    location = geolocator.reverse(team_location[i])\n",
    "    team_location[i] = location.raw['address']['state']\n",
    "\n",
    "#creating dict of every state and its covid restrictions based on article above (softer restrictions, heavier restrictions)    \n",
    "covid_restriction = {'Alabama':'softer restrictions',\n",
    "                     'Alaska':'softer restrictions',\n",
    "                     'Arizona':'softer restrictions',\n",
    "                     'Arkansas':'softer restrictions',\n",
    "                     'California':'heavier restrictions',\n",
    "                     'Colorado':'heavier restrictions',\n",
    "                     'Connecticut':'heavier restrictions',\n",
    "                     'Delaware':'heavier restrictions',\n",
    "                     'District of Columbia':'heavier restrictions',\n",
    "                     'Florida':'softer restrictions',\n",
    "                     'Georgia':'softer restrictions',\n",
    "                     'Hawaii':'heavier restrictions',\n",
    "                     'Idaho':'softer restrictions',\n",
    "                     'Illinois':'heavier restrictions',\n",
    "                     'Indiana':'softer restrictions',\n",
    "                     'Iowa':'softer restrictions',\n",
    "                     'Kansas':'softer restrictions',\n",
    "                     'Kentucky':'heavier restrictions',\n",
    "                     'Louisiana':'softer restrictions',\n",
    "                     'Maine':'heavier restrictions',\n",
    "                     'Maryland':'heavier restrictions',\n",
    "                     'Massachusetts':'heavier restrictions',\n",
    "                     'Michigan':'heavier restrictions',\n",
    "                     'Minnesota':'heavier restrictions',\n",
    "                     'Mississippi':'softer restrictions',\n",
    "                     'Missouri':'softer restrictions',\n",
    "                     'Montana':'softer restrictions',\n",
    "                     'Nebraska':'softer restrictions',\n",
    "                     'Nevada':'heavier restrictions',\n",
    "                     'New Hampshire':'softer restrictions',\n",
    "                     'New Jersey':'heavier restrictions',\n",
    "                     'New Mexico':'heavier restrictions',\n",
    "                     'New York':'heavier restrictions',\n",
    "                     'North Carolina':'heavier restrictions',\n",
    "                     'North Dakota':'softer restrictions',\n",
    "                     'Ohio':'softer restrictions',\n",
    "                     'Oklahoma':'softer restrictions',\n",
    "                     'Oregon':'heavier restrictions',\n",
    "                     'Pennsylvania':'heavier restrictions',\n",
    "                     'Rhode Island':'heavier restrictions',\n",
    "                     'South Carolina':'softer restrictions',\n",
    "                     'South Dakota':'softer restrictions',\n",
    "                     'Tennessee':'softer restrictions',\n",
    "                     'Texas':'heavier restrictions',\n",
    "                     'Utah':'softer restrictions',\n",
    "                     'Vermont':'heavier restrictions',\n",
    "                     'Virginia':'heavier restrictions',\n",
    "                     'Washington':'heavier restrictions',\n",
    "                     'West Virginia':'heavier restrictions',\n",
    "                     'Wisconsin':'softer restrictions',\n",
    "                     'Wyoming':'softer restrictions'}\n",
    "\n",
    "#creating dict to join team restrictions with state restrictions\n",
    "team_restrictions = dict()\n",
    "\n",
    "#retrieving info\n",
    "for i in team_location:\n",
    "    team_restrictions[i] = covid_restriction[team_location[i]]\n",
    "\n",
    "#setting values in dataframe for team1 and team2    \n",
    "df_copy['team1_covid_restrictions'] = None\n",
    "for i in range(0,len(df_copy)):\n",
    "    df_copy['team1_covid_restrictions'][i] = team_restrictions[df_copy['team1_teamname'][i]]\n",
    "    \n",
    "df_copy['team2_covid_restrictions'] = None\n",
    "for i in range(0,len(df_copy)):\n",
    "    df_copy['team2_covid_restrictions'][i] = team_restrictions[df_copy['team2_teamname'][i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sports Betting Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperating the first round from the rest of the round for sports betting\n",
    "df_non_first = df_copy[df_copy['First Round'] == 0]\n",
    "df_first = df_copy[df_copy['First Round'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Betting odds - Free API - 500 requests left\n",
    "import requests\n",
    "api_key = '27a095c312902861ebe8c688175e761e'\n",
    "url = 'https://api.the-odds-api.com/v3/odds?sport=basketball_ncaab&region=us&apiKey=27a095c312902861ebe8c688175e761e'\n",
    "response = requests.request('GET', url)\n",
    "\n",
    "import json\n",
    "betting_data = json.loads(response.text)['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def betting_odds(df, betting_data):\n",
    "    for index, row in df.iterrows():\n",
    "        team1_data = row['team1_teamname']\n",
    "        team2_data = row['team2_teamname']\n",
    "\n",
    "        temp_df = pd.DataFrame(columns=['team_API', 'team_DATA', 'Ratio', 'List_Location', 'Combination_Number'])\n",
    "        list_location = 0\n",
    "\n",
    "        for i in betting_data:\n",
    "\n",
    "            team1_api = i['teams'][0]\n",
    "            team2_api = i['teams'][1]\n",
    "\n",
    "            #1\n",
    "            Ratio = fuzz.ratio(team1_data.lower(),team1_api.lower())\n",
    "            temp_dict = {\n",
    "                'team_API': team1_api,\n",
    "                'team_DATA': team1_data,\n",
    "                'Ratio': Ratio,\n",
    "                'List_Location': list_location,\n",
    "                'Combination_Number': 1\n",
    "            }\n",
    "            temp_df = temp_df.append(temp_dict, ignore_index=True)\n",
    "\n",
    "            #2\n",
    "            Ratio = fuzz.ratio(team2_data.lower(),team1_api.lower())\n",
    "            temp_dict = {\n",
    "                'team_API': team1_api,\n",
    "                'team_DATA': team2_data,\n",
    "                'Ratio': Ratio,\n",
    "                'List_Location': list_location,\n",
    "                'Combination_Number': 2\n",
    "            }\n",
    "            temp_df = temp_df.append(temp_dict, ignore_index=True)\n",
    "\n",
    "            #3\n",
    "            Ratio = fuzz.ratio(team1_data.lower(),team2_api.lower())\n",
    "            temp_dict = {\n",
    "                'team_API': team2_api,\n",
    "                'team_DATA': team1_data,\n",
    "                'Ratio': Ratio,\n",
    "                'List_Location': list_location,\n",
    "                'Combination_Number': 3\n",
    "            }\n",
    "            temp_df = temp_df.append(temp_dict, ignore_index=True)\n",
    "\n",
    "            #4\n",
    "            Ratio = fuzz.ratio(team2_data.lower(),team2_api.lower())\n",
    "            temp_dict = {\n",
    "                'team_API': team2_api,\n",
    "                'team_DATA': team2_data,\n",
    "                'Ratio': Ratio,\n",
    "                'List_Location': list_location,\n",
    "                'Combination_Number': 4\n",
    "            }\n",
    "            temp_df = temp_df.append(temp_dict, ignore_index=True)\n",
    "\n",
    "            list_location += 1\n",
    "\n",
    "            team1 = temp_df[temp_df['team_DATA'] == team1_data].sort_values(['Ratio'], ascending=False).iloc[:1]\n",
    "            team2 = temp_df[temp_df['team_DATA'] == team2_data].sort_values(['Ratio'], ascending=False).iloc[:1]\n",
    "\n",
    "            temp_df = team1.append(team2, ignore_index=True)\n",
    "            \n",
    "            global team1_odd, team2_odd\n",
    "            \n",
    "            for i, r in temp_df.iterrows():\n",
    "                if r['Combination_Number'] == 1:\n",
    "                    team1_odd = betting_data[r['List_Location']]['sites'][0]['odds']['h2h'][0]\n",
    "\n",
    "                if r['Combination_Number'] == 2:\n",
    "                    team2_odd = betting_data[r['List_Location']]['sites'][0]['odds']['h2h'][0]\n",
    "\n",
    "                if r['Combination_Number'] == 3:\n",
    "                    team1_odd = betting_data[r['List_Location']]['sites'][0]['odds']['h2h'][1]\n",
    "\n",
    "                if r['Combination_Number'] == 4:\n",
    "                    team2_odd = betting_data[r['List_Location']]['sites'][0]['odds']['h2h'][1]\n",
    "\n",
    "\n",
    "            df.at[index,'team1_odd'] = team1_odd\n",
    "            df.at[index,'team2_odd'] = team2_odd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1598: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = infer_fill_value(value)\n",
      "C:\\Users\\Leonardo Luchetti\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1719: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "#calling the betting odds function to get the odds\n",
    "betting_odds(df_first, betting_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-56-bcda8f8f2e4d>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_non_first[['team1_odd','team2_odd']] = 0\n"
     ]
    }
   ],
   "source": [
    "#Set the betting odds to zero for both teams on the non-first round data. When the odds of two teams are equal the sports betting worlds aims them to be equal\n",
    "#So we will not affect their probability\n",
    "df_non_first[['team1_odd','team2_odd']] = 0\n",
    "\n",
    "#Append the first round and non first round dataframes\n",
    "final_2021_predictions = df_non_first.append(df_first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting the generated probabilities with Exogenous Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the function below we will adjust the probability (negavtively or positively) depending on the three variables: Dad's Intuition, COVID affected homeground, Sport Betting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_adjuster(df):\n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        # dad's intuition\n",
    "        if row['team1_dad_intuition'] == row['team2_dad_intuition']:\n",
    "            pass\n",
    "        \n",
    "        elif row['team1_dad_intuition'] == 'top' and row['team2_dad_intuition'] == 'bottom':\n",
    "            df.at[index, 'prob'] = row['prob'] + 0.0125\n",
    "        \n",
    "        elif row['team1_dad_intuition'] == 'top' and row['team2_dad_intuition'] == 'unranked':\n",
    "            df.at[index, 'prob'] = row['prob'] + 0.0125\n",
    "        \n",
    "        elif row['team1_dad_intuition'] == 'bottom' and row['team2_dad_intuition'] == 'top':\n",
    "            df.at[index, 'prob'] = row['prob'] - 0.0125\n",
    "        \n",
    "        elif row['team1_dad_intuition'] == 'bottom' and row['team2_dad_intuition'] == 'unranked':\n",
    "            pass\n",
    "        \n",
    "        elif row['team1_dad_intuition'] == 'unranked' and row['team2_dad_intuition'] == 'top':\n",
    "            df.at[index, 'prob'] = row['prob'] - 0.0125\n",
    "        \n",
    "        elif row['team1_dad_intuition'] == 'unranked' and row['team2_dad_intuition'] == 'bottom':\n",
    "            pass\n",
    "        \n",
    "        #COVID Affected Homeground\n",
    "        if row['team1_covid_restrictions'] == row['team2_covid_restrictions']:\n",
    "            pass\n",
    "        \n",
    "        elif row['team1_covid_restrictions'] == 'softer restrictions' and row['team2_covid_restrictions'] == 'heavier restrictions':\n",
    "            df.at[index, 'prob'] = row['prob'] + 0.0125\n",
    "            \n",
    "        elif row['team1_covid_restrictions'] == 'heavier restrictions' and row['team2_covid_restrictions'] == 'softer restrictions':\n",
    "            df.at[index, 'prob'] = row['prob'] - 0.0125\n",
    "            \n",
    "            \n",
    "        #Sports Betting\n",
    "        if row['team1_odd'] == row['team2_odd']:\n",
    "            pass\n",
    "        elif row['team1_odd'] < row['team2_odd']:\n",
    "            df.at[index, 'prob'] = row['prob'] + 0.025\n",
    "        elif row['team1_odd'] > row['team2_odd']:\n",
    "            df.at[index, 'prob'] = row['prob'] - 0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the probability adjuster function\n",
    "probability_adjuster(final_2021_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare final dataset for submission\n",
    "final_2021_predictions[['game_id', 'prob']].to_csv('final_submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
